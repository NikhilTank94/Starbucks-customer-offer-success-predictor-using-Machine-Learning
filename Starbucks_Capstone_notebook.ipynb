{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starbucks Capstone Challenge\n",
    "\n",
    "### Introduction\n",
    "\n",
    "This data set contains simulated data that mimics customer behavior on the Starbucks rewards mobile app. Once every few days, Starbucks sends out an offer to users of the mobile app. An offer can be merely an advertisement for a drink or an actual offer such as a discount or BOGO (buy one get one free). Some users might not receive any offer during certain weeks. \n",
    "\n",
    "Not all users receive the same offer, and that is the challenge to solve with this data set.\n",
    "\n",
    "Your task is to combine transaction, demographic and offer data to determine which demographic groups respond best to which offer type. This data set is a simplified version of the real Starbucks app because the underlying simulator only has one product whereas Starbucks actually sells dozens of products.\n",
    "\n",
    "Every offer has a validity period before the offer expires. As an example, a BOGO offer might be valid for only 5 days. You'll see in the data set that informational offers have a validity period even though these ads are merely providing information about a product; for example, if an informational offer has 7 days of validity, you can assume the customer is feeling the influence of the offer for 7 days after receiving the advertisement.\n",
    "\n",
    "You'll be given transactional data showing user purchases made on the app including the timestamp of purchase and the amount of money spent on a purchase. This transactional data also has a record for each offer that a user receives as well as a record for when a user actually views the offer. There are also records for when a user completes an offer. \n",
    "\n",
    "Keep in mind as well that someone using the app might make a purchase through the app without having received an offer or seen an offer.\n",
    "\n",
    "### Example\n",
    "\n",
    "To give an example, a user could receive a discount offer buy 10 dollars get 2 off on Monday. The offer is valid for 10 days from receipt. If the customer accumulates at least 10 dollars in purchases during the validity period, the customer completes the offer.\n",
    "\n",
    "However, there are a few things to watch out for in this data set. Customers do not opt into the offers that they receive; in other words, a user can receive an offer, never actually view the offer, and still complete the offer. For example, a user might receive the \"buy 10 dollars get 2 dollars off offer\", but the user never opens the offer during the 10 day validity period. The customer spends 15 dollars during those ten days. There will be an offer completion record in the data set; however, the customer was not influenced by the offer because the customer never viewed the offer.\n",
    "\n",
    "### Cleaning\n",
    "\n",
    "This makes data cleaning especially important and tricky.\n",
    "\n",
    "You'll also want to take into account that some demographic groups will make purchases even if they don't receive an offer. From a business perspective, if a customer is going to make a 10 dollar purchase without an offer anyway, you wouldn't want to send a buy 10 dollars get 2 dollars off offer. You'll want to try to assess what a certain demographic group will buy when not receiving any offers.\n",
    "\n",
    "### Final Advice\n",
    "\n",
    "Because this is a capstone project, you are free to analyze the data any way you see fit. For example, you could build a machine learning model that predicts how much someone will spend based on demographics and offer type. Or you could build a model that predicts whether or not someone will respond to an offer. Or, you don't need to build a machine learning model at all. You could develop a set of heuristics that determine what offer you should send to each customer (i.e., 75 percent of women customers who were 35 years old responded to offer A vs 40 percent from the same demographic to offer B, so send offer A)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Sets\n",
    "\n",
    "The data is contained in three files:\n",
    "\n",
    "* portfolio.json - containing offer ids and meta data about each offer (duration, type, etc.)\n",
    "* profile.json - demographic data for each customer\n",
    "* transcript.json - records for transactions, offers received, offers viewed, and offers completed\n",
    "\n",
    "Here is the schema and explanation of each variable in the files:\n",
    "\n",
    "**portfolio.json**\n",
    "* id (string) - offer id\n",
    "* offer_type (string) - type of offer ie BOGO, discount, informational\n",
    "* difficulty (int) - minimum required spend to complete an offer\n",
    "* reward (int) - reward given for completing an offer\n",
    "* duration (int) - time for offer to be open, in days\n",
    "* channels (list of strings)\n",
    "\n",
    "**profile.json**\n",
    "* age (int) - age of the customer \n",
    "* became_member_on (int) - date when customer created an app account\n",
    "* gender (str) - gender of the customer (note some entries contain 'O' for other rather than M or F)\n",
    "* id (str) - customer id\n",
    "* income (float) - customer's income\n",
    "\n",
    "**transcript.json**\n",
    "* event (str) - record description (ie transaction, offer received, offer viewed, etc.)\n",
    "* person (str) - customer id\n",
    "* time (int) - time in hours since start of test. The data begins at time t=0\n",
    "* value - (dict of strings) - either an offer id or transaction amount depending on the record\n",
    "\n",
    "**Note:** If you are using the workspace, you will need to go to the terminal and run the command `conda update pandas` before reading in the files. This is because the version of pandas in the workspace cannot read in the transcript.json file correctly, but the newest version of pandas can. You can access the termnal from the orange icon in the top left of this notebook.  \n",
    "\n",
    "You can see how to access the terminal and how the install works using the two images below.  First you need to access the terminal:\n",
    "\n",
    "<img src=\"pic1.png\"/>\n",
    "\n",
    "Then you will want to run the above command:\n",
    "\n",
    "<img src=\"pic2.png\"/>\n",
    "\n",
    "Finally, when you enter back into the notebook (use the jupyter icon again), you should be able to run the below cell without any errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "%matplotlib inline\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_col(col):\n",
    "    col = col.values.reshape(-1, 1).astype(\"float64\")\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    scaled_col = min_max_scaler.fit_transform(col)\n",
    "    return scaled_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reward</th>\n",
       "      <th>channels</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>duration</th>\n",
       "      <th>offer_type</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>[email, mobile, social]</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>bogo</td>\n",
       "      <td>ae264e3637204a6fb9bb56bc8210ddfd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>[web, email, mobile, social]</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>bogo</td>\n",
       "      <td>4d5c57ea9a6940dd891ad53e9dbe8da0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[web, email, mobile]</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>informational</td>\n",
       "      <td>3f207df678b143eea3cee63160fa8bed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>[web, email, mobile]</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>bogo</td>\n",
       "      <td>9b98b8c7a33c4b65b9aebfe6a799e6d9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[web, email]</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>discount</td>\n",
       "      <td>0b1e1539f2cc45b7b9fa7c272da2e1d7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reward                      channels  difficulty  duration     offer_type  \\\n",
       "0      10       [email, mobile, social]          10         7           bogo   \n",
       "1      10  [web, email, mobile, social]          10         5           bogo   \n",
       "2       0          [web, email, mobile]           0         4  informational   \n",
       "3       5          [web, email, mobile]           5         7           bogo   \n",
       "4       5                  [web, email]          20        10       discount   \n",
       "\n",
       "                                 id  \n",
       "0  ae264e3637204a6fb9bb56bc8210ddfd  \n",
       "1  4d5c57ea9a6940dd891ad53e9dbe8da0  \n",
       "2  3f207df678b143eea3cee63160fa8bed  \n",
       "3  9b98b8c7a33c4b65b9aebfe6a799e6d9  \n",
       "4  0b1e1539f2cc45b7b9fa7c272da2e1d7  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolio = pd.read_json('data/portfolio.json', orient='records', lines=True)\n",
    "portfolio.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_portfolio(filepath=\"data/portfolio.json\"):\n",
    "    # read in the json files\n",
    "    portfolio = pd.read_json(filepath, orient='records', lines=True)\n",
    "\n",
    "    # Step1: make columns for different offer\n",
    "    portfolio = pd.concat([\n",
    "        portfolio,\n",
    "        pd.get_dummies(portfolio[\"offer_type\"], prefix=\"offer_type\")\n",
    "    ], axis=1).drop([\"offer_type\"], axis=1)\n",
    "    \n",
    "    # Step2: for each channel-type make a new column\n",
    "    portfolio[\"channel_mobile\"] = portfolio[\"channels\"].apply(lambda x: int(\"mobile\" in x))\n",
    "    portfolio[\"channel_web\"] = portfolio[\"channels\"].apply(lambda x: int(\"web\" in x))\n",
    "    portfolio[\"channel_social\"] = portfolio[\"channels\"].apply(lambda x: int(\"social\" in x))\n",
    "    portfolio[\"channel_email\"] = portfolio[\"channels\"].apply(lambda x: int(\"email\" in x))\n",
    "    \n",
    "    # Step3: create new two ratio features\n",
    "    portfolio[\"difficulty_duration\"] = portfolio[\"difficulty\"] / portfolio[\"duration\"]\n",
    "    portfolio[\"reward_difficulty\"] = portfolio[\"reward\"] / portfolio[\"difficulty\"]\n",
    "    portfolio[\"reward_difficulty\"] = portfolio[\"reward_difficulty\"].fillna(0)\n",
    "    \n",
    "    # Final step: normalize columns\n",
    "    portfolio[\"reward\"] = normalize_col(portfolio[\"reward\"])\n",
    "    portfolio[\"difficulty\"] = normalize_col(portfolio[\"difficulty\"])\n",
    "    portfolio[\"duration\"] = normalize_col(portfolio[\"duration\"])    \n",
    "    \n",
    "    # drop channels\n",
    "    return portfolio.drop([\"channels\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reward</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>duration</th>\n",
       "      <th>id</th>\n",
       "      <th>offer_type_bogo</th>\n",
       "      <th>offer_type_discount</th>\n",
       "      <th>offer_type_informational</th>\n",
       "      <th>channel_mobile</th>\n",
       "      <th>channel_web</th>\n",
       "      <th>channel_social</th>\n",
       "      <th>channel_email</th>\n",
       "      <th>difficulty_duration</th>\n",
       "      <th>reward_difficulty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>ae264e3637204a6fb9bb56bc8210ddfd</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>4d5c57ea9a6940dd891ad53e9dbe8da0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>3f207df678b143eea3cee63160fa8bed</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>9b98b8c7a33c4b65b9aebfe6a799e6d9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0b1e1539f2cc45b7b9fa7c272da2e1d7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reward  difficulty  duration                                id  \\\n",
       "0     1.0        0.50  0.571429  ae264e3637204a6fb9bb56bc8210ddfd   \n",
       "1     1.0        0.50  0.285714  4d5c57ea9a6940dd891ad53e9dbe8da0   \n",
       "2     0.0        0.00  0.142857  3f207df678b143eea3cee63160fa8bed   \n",
       "3     0.5        0.25  0.571429  9b98b8c7a33c4b65b9aebfe6a799e6d9   \n",
       "4     0.5        1.00  1.000000  0b1e1539f2cc45b7b9fa7c272da2e1d7   \n",
       "\n",
       "   offer_type_bogo  offer_type_discount  offer_type_informational  \\\n",
       "0                1                    0                         0   \n",
       "1                1                    0                         0   \n",
       "2                0                    0                         1   \n",
       "3                1                    0                         0   \n",
       "4                0                    1                         0   \n",
       "\n",
       "   channel_mobile  channel_web  channel_social  channel_email  \\\n",
       "0               1            0               1              1   \n",
       "1               1            1               1              1   \n",
       "2               1            1               0              1   \n",
       "3               1            1               0              1   \n",
       "4               0            1               0              1   \n",
       "\n",
       "   difficulty_duration  reward_difficulty  \n",
       "0             1.428571               1.00  \n",
       "1             2.000000               1.00  \n",
       "2             0.000000               0.00  \n",
       "3             0.714286               1.00  \n",
       "4             2.000000               0.25  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the json files\n",
    "portfolio_df = process_portfolio()\n",
    "portfolio_df.head()\n",
    "# profile = pd.read_json('data/profile.json', orient='records', lines=True)\n",
    "# transcript = pd.read_json('data/transcript.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>id</th>\n",
       "      <th>became_member_on</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>118</td>\n",
       "      <td>68be06ca386d4c31939f3a4f0e3dd783</td>\n",
       "      <td>20170212</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>55</td>\n",
       "      <td>0610b486422d4921ae7d2bf64640c50b</td>\n",
       "      <td>20170715</td>\n",
       "      <td>112000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>118</td>\n",
       "      <td>38fe809add3b4fcf9315a9694bb96ff5</td>\n",
       "      <td>20180712</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>75</td>\n",
       "      <td>78afa995795e4d85b5d9ceeca43f5fef</td>\n",
       "      <td>20170509</td>\n",
       "      <td>100000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>118</td>\n",
       "      <td>a03223e636434f42ac4c3df47e8bac43</td>\n",
       "      <td>20170804</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender  age                                id  became_member_on    income\n",
       "0   None  118  68be06ca386d4c31939f3a4f0e3dd783          20170212       NaN\n",
       "1      F   55  0610b486422d4921ae7d2bf64640c50b          20170715  112000.0\n",
       "2   None  118  38fe809add3b4fcf9315a9694bb96ff5          20180712       NaN\n",
       "3      F   75  78afa995795e4d85b5d9ceeca43f5fef          20170509  100000.0\n",
       "4   None  118  a03223e636434f42ac4c3df47e8bac43          20170804       NaN"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile_df = pd.read_json('data/profile.json', orient='records', lines=True)\n",
    "profile_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_profile(filepath='data/profile.json'):\n",
    "    # read in the json files\n",
    "    profile = pd.read_json(filepath, orient='records', lines=True)\n",
    "    \n",
    "    # Step1: encoding for gender\n",
    "    profile = pd.concat([profile, \n",
    "                         pd.get_dummies(profile['gender'], prefix='gender', dummy_na=True)\n",
    "                        ], axis=1).drop([\"gender\"], axis=1)\n",
    "    \n",
    "    # Step2: fillin nan income with median\n",
    "    profile = profile.fillna(\n",
    "        {\"income\": profile.income.dropna().median()})\n",
    "    \n",
    "    # Step3: fillin nan age with 118\n",
    "    profile.age = profile.age.apply(lambda x: None if x == 118 else x)\n",
    "    profile = profile.fillna({\"age\": profile.age.dropna().median()})\n",
    "    \n",
    "    # Step4: convert date to unix timestamp\n",
    "    profile.became_member_on = pd.to_datetime(\n",
    "        profile.became_member_on, format='%Y%m%d').astype(np.int64) // 10**9\n",
    "    \n",
    "    # normalize\n",
    "    profile[\"income\"] = normalize_col(profile[\"income\"])\n",
    "    profile[\"age\"] = normalize_col(profile[\"age\"])\n",
    "    profile[\"became_member_on\"] = normalize_col(profile[\"became_member_on\"])\n",
    "\n",
    "    \n",
    "    return profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>id</th>\n",
       "      <th>became_member_on</th>\n",
       "      <th>income</th>\n",
       "      <th>gender_F</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>gender_O</th>\n",
       "      <th>gender_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.445783</td>\n",
       "      <td>68be06ca386d4c31939f3a4f0e3dd783</td>\n",
       "      <td>0.709819</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.445783</td>\n",
       "      <td>0610b486422d4921ae7d2bf64640c50b</td>\n",
       "      <td>0.793747</td>\n",
       "      <td>0.911111</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.445783</td>\n",
       "      <td>38fe809add3b4fcf9315a9694bb96ff5</td>\n",
       "      <td>0.992320</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.686747</td>\n",
       "      <td>78afa995795e4d85b5d9ceeca43f5fef</td>\n",
       "      <td>0.756994</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.445783</td>\n",
       "      <td>a03223e636434f42ac4c3df47e8bac43</td>\n",
       "      <td>0.804717</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age                                id  became_member_on    income  \\\n",
       "0  0.445783  68be06ca386d4c31939f3a4f0e3dd783          0.709819  0.377778   \n",
       "1  0.445783  0610b486422d4921ae7d2bf64640c50b          0.793747  0.911111   \n",
       "2  0.445783  38fe809add3b4fcf9315a9694bb96ff5          0.992320  0.377778   \n",
       "3  0.686747  78afa995795e4d85b5d9ceeca43f5fef          0.756994  0.777778   \n",
       "4  0.445783  a03223e636434f42ac4c3df47e8bac43          0.804717  0.377778   \n",
       "\n",
       "   gender_F  gender_M  gender_O  gender_nan  \n",
       "0         0         0         0           1  \n",
       "1         1         0         0           0  \n",
       "2         0         0         0           1  \n",
       "3         1         0         0           0  \n",
       "4         0         0         0           1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile_df = process_profile()\n",
    "profile_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>offer_id</th>\n",
       "      <th>offer_type</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>amount</th>\n",
       "      <th>receive_time</th>\n",
       "      <th>view_time</th>\n",
       "      <th>complete_time</th>\n",
       "      <th>expected_complete_time</th>\n",
       "      <th>is_in_expected_complete_time</th>\n",
       "      <th>is_enough_amount</th>\n",
       "      <th>is_view_event</th>\n",
       "      <th>is_complete_event</th>\n",
       "      <th>is_complete</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0009655768c64bdeb2e877511632db8f</td>\n",
       "      <td>5a8bc65990b245e5a138643cd4eb9837</td>\n",
       "      <td>informational</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.16</td>\n",
       "      <td>168</td>\n",
       "      <td>192.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>240.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0009655768c64bdeb2e877511632db8f</td>\n",
       "      <td>3f207df678b143eea3cee63160fa8bed</td>\n",
       "      <td>informational</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.57</td>\n",
       "      <td>336</td>\n",
       "      <td>372.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>432.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0009655768c64bdeb2e877511632db8f</td>\n",
       "      <td>f19421c1d4aa40978ebb69ca19b0e20d</td>\n",
       "      <td>bogo</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.57</td>\n",
       "      <td>408</td>\n",
       "      <td>456.0</td>\n",
       "      <td>414.0</td>\n",
       "      <td>528.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0009655768c64bdeb2e877511632db8f</td>\n",
       "      <td>fafdcd668e3743c1bb461111dcafc2a4</td>\n",
       "      <td>discount</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.11</td>\n",
       "      <td>504</td>\n",
       "      <td>540.0</td>\n",
       "      <td>528.0</td>\n",
       "      <td>744.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0009655768c64bdeb2e877511632db8f</td>\n",
       "      <td>2906b810c7d4411798c6938adc9daaa5</td>\n",
       "      <td>discount</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.27</td>\n",
       "      <td>576</td>\n",
       "      <td>NaN</td>\n",
       "      <td>576.0</td>\n",
       "      <td>744.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             person                          offer_id  \\\n",
       "0  0009655768c64bdeb2e877511632db8f  5a8bc65990b245e5a138643cd4eb9837   \n",
       "1  0009655768c64bdeb2e877511632db8f  3f207df678b143eea3cee63160fa8bed   \n",
       "2  0009655768c64bdeb2e877511632db8f  f19421c1d4aa40978ebb69ca19b0e20d   \n",
       "3  0009655768c64bdeb2e877511632db8f  fafdcd668e3743c1bb461111dcafc2a4   \n",
       "4  0009655768c64bdeb2e877511632db8f  2906b810c7d4411798c6938adc9daaa5   \n",
       "\n",
       "      offer_type  difficulty  amount  receive_time  view_time  complete_time  \\\n",
       "0  informational         0.0   22.16           168      192.0            NaN   \n",
       "1  informational         0.0    8.57           336      372.0            NaN   \n",
       "2           bogo         5.0    8.57           408      456.0          414.0   \n",
       "3       discount        10.0   14.11           504      540.0          528.0   \n",
       "4       discount        10.0   10.27           576        NaN          576.0   \n",
       "\n",
       "   expected_complete_time  is_in_expected_complete_time  is_enough_amount  \\\n",
       "0                   240.0                         False              True   \n",
       "1                   432.0                         False              True   \n",
       "2                   528.0                          True              True   \n",
       "3                   744.0                          True              True   \n",
       "4                   744.0                          True              True   \n",
       "\n",
       "   is_view_event  is_complete_event  is_complete  \n",
       "0           True              False         True  \n",
       "1           True              False         True  \n",
       "2           True               True         True  \n",
       "3           True               True         True  \n",
       "4          False               True        False  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_df = pd.read_csv('data/processed_transcript.csv')\n",
    "transcript_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76277, 14)\n"
     ]
    }
   ],
   "source": [
    "print(transcript_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge three tables\n",
    "df = transcript_df[[\"person\", \"offer_id\", \"is_complete\"]].\\\n",
    "merge(profile_df, left_on=\"person\", right_on=\"id\").drop([\"id\", \"person\"], axis=1).\\\n",
    "merge(portfolio_df, left_on=\"offer_id\", right_on=\"id\").drop([\"id\", \"offer_id\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make is_complete 1 or 0\n",
    "df.is_complete = df.is_complete.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76277, 20)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_complete</th>\n",
       "      <th>age</th>\n",
       "      <th>became_member_on</th>\n",
       "      <th>income</th>\n",
       "      <th>gender_F</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>gender_O</th>\n",
       "      <th>gender_nan</th>\n",
       "      <th>reward</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>duration</th>\n",
       "      <th>offer_type_bogo</th>\n",
       "      <th>offer_type_discount</th>\n",
       "      <th>offer_type_informational</th>\n",
       "      <th>channel_mobile</th>\n",
       "      <th>channel_web</th>\n",
       "      <th>channel_social</th>\n",
       "      <th>channel_email</th>\n",
       "      <th>difficulty_duration</th>\n",
       "      <th>reward_difficulty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.180723</td>\n",
       "      <td>0.747120</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.265060</td>\n",
       "      <td>0.891388</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.493976</td>\n",
       "      <td>0.520570</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.072289</td>\n",
       "      <td>0.658804</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.096386</td>\n",
       "      <td>0.780581</td>\n",
       "      <td>0.477778</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_complete       age  became_member_on    income  gender_F  gender_M  \\\n",
       "0            1  0.180723          0.747120  0.466667         0         1   \n",
       "1            0  0.265060          0.891388  0.300000         0         0   \n",
       "2            1  0.493976          0.520570  0.666667         1         0   \n",
       "3            1  0.072289          0.658804  0.333333         1         0   \n",
       "4            1  0.096386          0.780581  0.477778         1         0   \n",
       "\n",
       "   gender_O  gender_nan  reward  difficulty  duration  offer_type_bogo  \\\n",
       "0         0           0     0.0         0.0       0.0                0   \n",
       "1         1           0     0.0         0.0       0.0                0   \n",
       "2         0           0     0.0         0.0       0.0                0   \n",
       "3         0           0     0.0         0.0       0.0                0   \n",
       "4         0           0     0.0         0.0       0.0                0   \n",
       "\n",
       "   offer_type_discount  offer_type_informational  channel_mobile  channel_web  \\\n",
       "0                    0                         1               1            0   \n",
       "1                    0                         1               1            0   \n",
       "2                    0                         1               1            0   \n",
       "3                    0                         1               1            0   \n",
       "4                    0                         1               1            0   \n",
       "\n",
       "   channel_social  channel_email  difficulty_duration  reward_difficulty  \n",
       "0               1              1                  0.0                0.0  \n",
       "1               1              1                  0.0                0.0  \n",
       "2               1              1                  0.0                0.0  \n",
       "3               1              1                  0.0                0.0  \n",
       "4               1              1                  0.0                0.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train/test\n",
    "def train_test_split(df, train_frac= 0.7, seed=666):\n",
    "    '''Randomly shuffle the data and split it into training and test features and labels using the train_frac\n",
    "       :return: Two tuples (in order): (train_features, train_labels), (test_features, test_labels)\n",
    "       '''\n",
    "    \n",
    "    # shuffle and break the data\n",
    "    df_matrix = df.values\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(df_matrix)\n",
    "    \n",
    "    train_size = int(df_matrix.shape[0] * train_frac)\n",
    "    train_features = df_matrix[:train_size, 1:]\n",
    "    train_labels = df_matrix[:train_size, 0]\n",
    "    \n",
    "    test_features = df_matrix[train_size:, 1:]\n",
    "    test_labels = df_matrix[train_size:, 0]\n",
    "    \n",
    "    return (train_features, train_labels), (test_features, test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_x, train_y), (test_x, test_y) = train_test_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53393, 19) (53393,)\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape, train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22884, 19) (22884,)\n"
     ]
    }
   ],
   "source": [
    "print(test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uploading the Data to S3 and making a local copy of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([\n",
    "    pd.DataFrame(train_y), \n",
    "    pd.DataFrame(train_x)\n",
    "], axis=1).to_csv(\"data/train.csv\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([\n",
    "    pd.DataFrame(test_y), \n",
    "    pd.DataFrame(test_x)\n",
    "], axis=1).to_csv(\"data/test.csv\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(test_x).to_csv(\"data/test_x.csv\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "session = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "prefix = 'starbucks-xgboost'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-2-290062341908/starbucks-xgboost/train.csv'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_location = session.upload_data(\"data/train.csv\", key_prefix=prefix)\n",
    "train_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-2-290062341908/starbucks-xgboost/test_x.csv'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_location = session.upload_data(\"data/test_x.csv\", key_prefix=prefix)\n",
    "test_location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'get_image_uri' method will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n",
      "There is a more up to date SageMaker XGBoost image. To use the newer image, please set 'repo_version'='1.0-1'. For example:\n",
      "\tget_image_uri(region, 'xgboost', '1.0-1').\n",
      "Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-01 23:11:34 Starting - Starting the training job...\n",
      "2020-08-01 23:11:36 Starting - Launching requested ML instances......\n",
      "2020-08-01 23:12:38 Starting - Preparing the instances for training...\n",
      "2020-08-01 23:13:28 Downloading - Downloading input data...\n",
      "2020-08-01 23:14:02 Training - Training image download completed. Training in progress..\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[2020-08-01:23:14:03:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[34m[2020-08-01:23:14:03:INFO] Path /opt/ml/input/data/validation does not exist!\u001b[0m\n",
      "\u001b[34m[2020-08-01:23:14:03:INFO] File size need to be processed in the node: 7.56mb. Available memory size in the node: 8491.77mb\u001b[0m\n",
      "\u001b[34m[2020-08-01:23:14:03:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[23:14:03] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[23:14:03] 53393x19 matrix with 1014467 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[23:14:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[0]#011train-error:0.306726\u001b[0m\n",
      "\u001b[34mWill train until train-error hasn't improved in 10 rounds.\u001b[0m\n",
      "\u001b[34m[23:14:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[1]#011train-error:0.303692\u001b[0m\n",
      "\u001b[34m[23:14:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2]#011train-error:0.302437\u001b[0m\n",
      "\u001b[34m[23:14:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[3]#011train-error:0.298728\u001b[0m\n",
      "\u001b[34m[23:14:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[4]#011train-error:0.291574\u001b[0m\n",
      "\u001b[34m[23:14:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[5]#011train-error:0.291012\u001b[0m\n",
      "\u001b[34m[23:14:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[6]#011train-error:0.290562\u001b[0m\n",
      "\u001b[34m[23:14:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[7]#011train-error:0.290094\u001b[0m\n",
      "\u001b[34m[23:14:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[8]#011train-error:0.287585\u001b[0m\n",
      "\u001b[34m[23:14:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[9]#011train-error:0.288221\u001b[0m\n",
      "\u001b[34m[23:14:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[10]#011train-error:0.286536\u001b[0m\n",
      "\u001b[34m[23:14:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[11]#011train-error:0.28676\u001b[0m\n",
      "\u001b[34m[23:14:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[12]#011train-error:0.286629\u001b[0m\n",
      "\u001b[34m[23:14:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[13]#011train-error:0.28382\u001b[0m\n",
      "\u001b[34m[23:14:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[14]#011train-error:0.28264\u001b[0m\n",
      "\u001b[34m[23:14:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[15]#011train-error:0.282116\u001b[0m\n",
      "\u001b[34m[23:14:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 30 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[16]#011train-error:0.281835\u001b[0m\n",
      "\u001b[34m[23:14:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[17]#011train-error:0.280655\u001b[0m\n",
      "\u001b[34m[23:14:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18]#011train-error:0.280243\u001b[0m\n",
      "\u001b[34m[23:14:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[19]#011train-error:0.279812\u001b[0m\n",
      "\u001b[34m[23:14:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[20]#011train-error:0.27955\u001b[0m\n",
      "\u001b[34m[23:14:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[21]#011train-error:0.279512\u001b[0m\n",
      "\u001b[34m[23:14:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[22]#011train-error:0.279119\u001b[0m\n",
      "\u001b[34m[23:14:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[23]#011train-error:0.278875\u001b[0m\n",
      "\u001b[34m[23:14:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[24]#011train-error:0.278314\u001b[0m\n",
      "\u001b[34m[23:14:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[25]#011train-error:0.277864\u001b[0m\n",
      "\u001b[34m[23:14:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[26]#011train-error:0.277059\u001b[0m\n",
      "\u001b[34m[23:14:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[27]#011train-error:0.276909\u001b[0m\n",
      "\u001b[34m[23:14:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[28]#011train-error:0.27674\u001b[0m\n",
      "\u001b[34m[23:14:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[29]#011train-error:0.276459\u001b[0m\n",
      "\u001b[34m[23:14:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[30]#011train-error:0.276291\u001b[0m\n",
      "\u001b[34m[23:14:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[31]#011train-error:0.276216\u001b[0m\n",
      "\u001b[34m[23:14:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[32]#011train-error:0.276253\u001b[0m\n",
      "\u001b[34m[23:14:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[33]#011train-error:0.276029\u001b[0m\n",
      "\u001b[34m[23:14:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[34]#011train-error:0.275785\u001b[0m\n",
      "\u001b[34m[23:14:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[35]#011train-error:0.275223\u001b[0m\n",
      "\u001b[34m[23:14:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[36]#011train-error:0.274924\u001b[0m\n",
      "\u001b[34m[23:14:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[37]#011train-error:0.274605\u001b[0m\n",
      "\u001b[34m[23:14:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[38]#011train-error:0.274399\u001b[0m\n",
      "\u001b[34m[23:14:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[39]#011train-error:0.274193\u001b[0m\n",
      "\u001b[34m[23:14:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[40]#011train-error:0.273837\u001b[0m\n",
      "\u001b[34m[23:14:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[41]#011train-error:0.273238\u001b[0m\n",
      "\u001b[34m[23:14:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[42]#011train-error:0.27292\u001b[0m\n",
      "\u001b[34m[23:14:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[43]#011train-error:0.272264\u001b[0m\n",
      "\u001b[34m[23:14:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[44]#011train-error:0.272208\u001b[0m\n",
      "\u001b[34m[23:14:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[45]#011train-error:0.272058\u001b[0m\n",
      "\u001b[34m[23:14:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[46]#011train-error:0.272058\u001b[0m\n",
      "\u001b[34m[23:14:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[47]#011train-error:0.271721\u001b[0m\n",
      "\u001b[34m[23:14:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[48]#011train-error:0.271609\u001b[0m\n",
      "\u001b[34m[23:14:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[49]#011train-error:0.271384\u001b[0m\n",
      "\u001b[34m[23:14:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 26 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[50]#011train-error:0.271047\u001b[0m\n",
      "\u001b[34m[23:14:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[51]#011train-error:0.270972\u001b[0m\n",
      "\u001b[34m[23:14:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[52]#011train-error:0.271047\u001b[0m\n",
      "\u001b[34m[23:14:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[53]#011train-error:0.270841\u001b[0m\n",
      "\u001b[34m[23:14:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[54]#011train-error:0.270485\u001b[0m\n",
      "\u001b[34m[23:14:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[55]#011train-error:0.270504\u001b[0m\n",
      "\u001b[34m[23:14:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[56]#011train-error:0.270279\u001b[0m\n",
      "\u001b[34m[23:14:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[57]#011train-error:0.270241\u001b[0m\n",
      "\u001b[34m[23:14:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 18 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[58]#011train-error:0.270241\u001b[0m\n",
      "\u001b[34m[23:14:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[59]#011train-error:0.270054\u001b[0m\n",
      "\u001b[34m[23:14:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[60]#011train-error:0.269942\u001b[0m\n",
      "\u001b[34m[23:14:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[61]#011train-error:0.270035\u001b[0m\n",
      "\u001b[34m[23:14:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[62]#011train-error:0.269904\u001b[0m\n",
      "\u001b[34m[23:14:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[63]#011train-error:0.269361\u001b[0m\n",
      "\u001b[34m[23:14:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[64]#011train-error:0.269567\u001b[0m\n",
      "\u001b[34m[23:14:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[65]#011train-error:0.269286\u001b[0m\n",
      "\u001b[34m[23:14:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[66]#011train-error:0.26893\u001b[0m\n",
      "\u001b[34m[23:14:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[67]#011train-error:0.268237\u001b[0m\n",
      "\u001b[34m[23:14:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[68]#011train-error:0.268069\u001b[0m\n",
      "\u001b[34m[23:14:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[69]#011train-error:0.268331\u001b[0m\n",
      "\u001b[34m[23:14:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[70]#011train-error:0.267732\u001b[0m\n",
      "\u001b[34m[23:14:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[71]#011train-error:0.267676\u001b[0m\n",
      "\u001b[34m[23:14:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[72]#011train-error:0.267245\u001b[0m\n",
      "\u001b[34m[23:14:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[73]#011train-error:0.26732\u001b[0m\n",
      "\u001b[34m[23:14:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[74]#011train-error:0.267282\u001b[0m\n",
      "\u001b[34m[23:14:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[75]#011train-error:0.266739\u001b[0m\n",
      "\u001b[34m[23:14:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[76]#011train-error:0.266627\u001b[0m\n",
      "\u001b[34m[23:14:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[77]#011train-error:0.266645\u001b[0m\n",
      "\u001b[34m[23:14:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[78]#011train-error:0.266496\u001b[0m\n",
      "\u001b[34m[23:14:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[79]#011train-error:0.266121\u001b[0m\n",
      "\u001b[34m[23:14:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 32 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[80]#011train-error:0.265672\u001b[0m\n",
      "\u001b[34m[23:14:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 26 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[81]#011train-error:0.26599\u001b[0m\n",
      "\u001b[34m[23:14:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[82]#011train-error:0.265934\u001b[0m\n",
      "\u001b[34m[23:14:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[83]#011train-error:0.265971\u001b[0m\n",
      "\u001b[34m[23:14:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[84]#011train-error:0.265578\u001b[0m\n",
      "\u001b[34m[23:14:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[85]#011train-error:0.265578\u001b[0m\n",
      "\u001b[34m[23:14:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[86]#011train-error:0.265409\u001b[0m\n",
      "\u001b[34m[23:14:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[87]#011train-error:0.265409\u001b[0m\n",
      "\u001b[34m[23:14:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 30 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[88]#011train-error:0.265934\u001b[0m\n",
      "\u001b[34m[23:14:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[89]#011train-error:0.265372\u001b[0m\n",
      "\u001b[34m[23:14:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[90]#011train-error:0.265035\u001b[0m\n",
      "\u001b[34m[23:14:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[91]#011train-error:0.265016\u001b[0m\n",
      "\u001b[34m[23:14:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[92]#011train-error:0.264885\u001b[0m\n",
      "\u001b[34m[23:14:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[93]#011train-error:0.264529\u001b[0m\n",
      "\u001b[34m[23:14:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[94]#011train-error:0.264492\u001b[0m\n",
      "\u001b[34m[23:14:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[95]#011train-error:0.264023\u001b[0m\n",
      "\u001b[34m[23:14:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[96]#011train-error:0.264042\u001b[0m\n",
      "\u001b[34m[23:14:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[97]#011train-error:0.263817\u001b[0m\n",
      "\u001b[34m[23:14:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 28 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[98]#011train-error:0.263668\u001b[0m\n",
      "\u001b[34m[23:14:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[99]#011train-error:0.263686\u001b[0m\n",
      "\u001b[34m[23:14:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[100]#011train-error:0.26363\u001b[0m\n",
      "\u001b[34m[23:14:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[101]#011train-error:0.263705\u001b[0m\n",
      "\u001b[34m[23:14:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[102]#011train-error:0.263443\u001b[0m\n",
      "\u001b[34m[23:14:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[103]#011train-error:0.263162\u001b[0m\n",
      "\u001b[34m[23:14:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[104]#011train-error:0.263031\u001b[0m\n",
      "\u001b[34m[23:14:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[105]#011train-error:0.262712\u001b[0m\n",
      "\u001b[34m[23:14:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[106]#011train-error:0.262394\u001b[0m\n",
      "\u001b[34m[23:14:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[107]#011train-error:0.261982\u001b[0m\n",
      "\u001b[34m[23:14:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 16 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[108]#011train-error:0.261926\u001b[0m\n",
      "\u001b[34m[23:14:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[109]#011train-error:0.261776\u001b[0m\n",
      "\u001b[34m[23:14:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[110]#011train-error:0.261701\u001b[0m\n",
      "\u001b[34m[23:14:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[111]#011train-error:0.261982\u001b[0m\n",
      "\u001b[34m[23:14:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[112]#011train-error:0.261907\u001b[0m\n",
      "\u001b[34m[23:14:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[113]#011train-error:0.26157\u001b[0m\n",
      "\u001b[34m[23:14:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[114]#011train-error:0.261664\u001b[0m\n",
      "\u001b[34m[23:14:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 30 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[115]#011train-error:0.261682\u001b[0m\n",
      "\u001b[34m[23:14:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 28 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[116]#011train-error:0.261326\u001b[0m\n",
      "\u001b[34m[23:14:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[117]#011train-error:0.261064\u001b[0m\n",
      "\u001b[34m[23:14:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[118]#011train-error:0.260746\u001b[0m\n",
      "\u001b[34m[23:14:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[119]#011train-error:0.260671\u001b[0m\n",
      "\u001b[34m[23:14:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[120]#011train-error:0.260708\u001b[0m\n",
      "\u001b[34m[23:14:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[121]#011train-error:0.260802\u001b[0m\n",
      "\u001b[34m[23:14:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 50 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[122]#011train-error:0.260839\u001b[0m\n",
      "\u001b[34m[23:14:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[123]#011train-error:0.260708\u001b[0m\n",
      "\u001b[34m[23:14:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 32 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[124]#011train-error:0.260727\u001b[0m\n",
      "\u001b[34m[23:14:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[125]#011train-error:0.260577\u001b[0m\n",
      "\u001b[34m[23:14:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 32 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[126]#011train-error:0.260727\u001b[0m\n",
      "\u001b[34m[23:14:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[127]#011train-error:0.260371\u001b[0m\n",
      "\u001b[34m[23:14:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[128]#011train-error:0.260446\u001b[0m\n",
      "\u001b[34m[23:14:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[129]#011train-error:0.260465\u001b[0m\n",
      "\u001b[34m[23:14:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[130]#011train-error:0.260015\u001b[0m\n",
      "\u001b[34m[23:14:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[131]#011train-error:0.25994\u001b[0m\n",
      "\u001b[34m[23:14:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[132]#011train-error:0.259903\u001b[0m\n",
      "\u001b[34m[23:14:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 34 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[133]#011train-error:0.259847\u001b[0m\n",
      "\u001b[34m[23:14:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 18 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[134]#011train-error:0.259903\u001b[0m\n",
      "\u001b[34m[23:14:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[135]#011train-error:0.259678\u001b[0m\n",
      "\u001b[34m[23:14:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 32 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[136]#011train-error:0.259491\u001b[0m\n",
      "\u001b[34m[23:14:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 32 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[137]#011train-error:0.259716\u001b[0m\n",
      "\u001b[34m[23:14:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 26 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[138]#011train-error:0.259528\u001b[0m\n",
      "\u001b[34m[23:14:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[139]#011train-error:0.259285\u001b[0m\n",
      "\u001b[34m[23:14:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[140]#011train-error:0.258929\u001b[0m\n",
      "\u001b[34m[23:14:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 30 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[141]#011train-error:0.258835\u001b[0m\n",
      "\u001b[34m[23:14:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 26 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[142]#011train-error:0.258761\u001b[0m\n",
      "\u001b[34m[23:14:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[143]#011train-error:0.258423\u001b[0m\n",
      "\u001b[34m[23:14:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 26 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[144]#011train-error:0.258536\u001b[0m\n",
      "\u001b[34m[23:14:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[145]#011train-error:0.258423\u001b[0m\n",
      "\u001b[34m[23:14:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[146]#011train-error:0.258217\u001b[0m\n",
      "\u001b[34m[23:14:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[147]#011train-error:0.257862\u001b[0m\n",
      "\u001b[34m[23:14:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[148]#011train-error:0.257375\u001b[0m\n",
      "\u001b[34m[23:14:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 26 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[149]#011train-error:0.257431\u001b[0m\n",
      "\u001b[34m[23:14:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[150]#011train-error:0.2573\u001b[0m\n",
      "\u001b[34m[23:14:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 28 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[151]#011train-error:0.256963\u001b[0m\n",
      "\u001b[34m[23:14:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[152]#011train-error:0.256682\u001b[0m\n",
      "\u001b[34m[23:14:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 28 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[153]#011train-error:0.256888\u001b[0m\n",
      "\u001b[34m[23:14:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 26 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[154]#011train-error:0.256963\u001b[0m\n",
      "\u001b[34m[23:14:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 26 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[155]#011train-error:0.256682\u001b[0m\n",
      "\u001b[34m[23:14:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[156]#011train-error:0.256363\u001b[0m\n",
      "\u001b[34m[23:14:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 26 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[157]#011train-error:0.256363\u001b[0m\n",
      "\u001b[34m[23:14:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[158]#011train-error:0.256363\u001b[0m\n",
      "\u001b[34m[23:14:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[159]#011train-error:0.256438\u001b[0m\n",
      "\u001b[34m[23:14:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 28 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[160]#011train-error:0.256419\u001b[0m\n",
      "\u001b[34m[23:14:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 26 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[161]#011train-error:0.256438\u001b[0m\n",
      "\u001b[34m[23:14:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 30 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[162]#011train-error:0.256438\u001b[0m\n",
      "\u001b[34m[23:14:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[163]#011train-error:0.256213\u001b[0m\n",
      "\u001b[34m[23:14:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 26 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[164]#011train-error:0.256382\u001b[0m\n",
      "\u001b[34m[23:14:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[165]#011train-error:0.25655\u001b[0m\n",
      "\u001b[34m[23:14:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[166]#011train-error:0.256494\u001b[0m\n",
      "\u001b[34m[23:14:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[167]#011train-error:0.256363\u001b[0m\n",
      "\u001b[34m[23:14:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 22 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[168]#011train-error:0.256401\u001b[0m\n",
      "\u001b[34m[23:14:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[169]#011train-error:0.256232\u001b[0m\n",
      "\u001b[34m[23:14:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 28 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[170]#011train-error:0.256082\u001b[0m\n",
      "\u001b[34m[23:14:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[171]#011train-error:0.255801\u001b[0m\n",
      "\u001b[34m[23:14:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[172]#011train-error:0.255689\u001b[0m\n",
      "\u001b[34m[23:14:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 22 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[173]#011train-error:0.255783\u001b[0m\n",
      "\u001b[34m[23:14:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 38 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[174]#011train-error:0.25582\u001b[0m\n",
      "\u001b[34m[23:14:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[175]#011train-error:0.255445\u001b[0m\n",
      "\u001b[34m[23:14:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 32 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[176]#011train-error:0.255577\u001b[0m\n",
      "\u001b[34m[23:14:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 30 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[177]#011train-error:0.255352\u001b[0m\n",
      "\u001b[34m[23:14:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[178]#011train-error:0.255333\u001b[0m\n",
      "\u001b[34m[23:14:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 20 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[179]#011train-error:0.255296\u001b[0m\n",
      "\u001b[34m[23:14:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[180]#011train-error:0.255015\u001b[0m\n",
      "\u001b[34m[23:14:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[181]#011train-error:0.254734\u001b[0m\n",
      "\u001b[34m[23:14:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[182]#011train-error:0.254621\u001b[0m\n",
      "\u001b[34m[23:14:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[183]#011train-error:0.254359\u001b[0m\n",
      "\u001b[34m[23:14:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 28 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[184]#011train-error:0.254097\u001b[0m\n",
      "\u001b[34m[23:14:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[185]#011train-error:0.25391\u001b[0m\n",
      "\u001b[34m[23:14:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[186]#011train-error:0.253872\u001b[0m\n",
      "\u001b[34m[23:14:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[187]#011train-error:0.25346\u001b[0m\n",
      "\u001b[34m[23:14:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[188]#011train-error:0.253498\u001b[0m\n",
      "\u001b[34m[23:14:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 26 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[189]#011train-error:0.253516\u001b[0m\n",
      "\u001b[34m[23:14:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 26 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[190]#011train-error:0.253629\u001b[0m\n",
      "\u001b[34m[23:14:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[191]#011train-error:0.253685\u001b[0m\n",
      "\u001b[34m[23:14:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[192]#011train-error:0.25376\u001b[0m\n",
      "\u001b[34m[23:14:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[193]#011train-error:0.253535\u001b[0m\n",
      "\u001b[34m[23:14:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[194]#011train-error:0.253516\u001b[0m\n",
      "\u001b[34m[23:14:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[195]#011train-error:0.253629\u001b[0m\n",
      "\u001b[34m[23:14:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[196]#011train-error:0.253647\u001b[0m\n",
      "\u001b[34m[23:14:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[197]#011train-error:0.25361\u001b[0m\n",
      "\u001b[34mStopping. Best iteration:\u001b[0m\n",
      "\u001b[34m[187]#011train-error:0.25346\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-08-01 23:14:19 Uploading - Uploading generated training model\n",
      "2020-08-01 23:14:19 Completed - Training job completed\n",
      "Training seconds: 51\n",
      "Billable seconds: 51\n"
     ]
    }
   ],
   "source": [
    "container = get_image_uri(session.boto_region_name, 'xgboost')\n",
    "\n",
    "xgb = sagemaker.estimator.Estimator(\n",
    "    container, # The name of the training container\n",
    "    role,      # The IAM role to use (our current role in this case)\n",
    "    train_instance_count=1, # The number of instances to use for training\n",
    "    train_instance_type='ml.m4.xlarge', # The type of instance ot use for training\n",
    "    output_path=f's3://{session.default_bucket()}/{prefix}/output',\n",
    "                                        # Where to save the output (the model artifacts)\n",
    "    sagemaker_session=session) # The current SageMaker session\n",
    "\n",
    "\n",
    "# hyperparameters\n",
    "xgb.set_hyperparameters(max_depth=5,\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        objective='binary:logistic',\n",
    "                        early_stopping_rounds=10,\n",
    "                        num_round=200)\n",
    "\n",
    "\n",
    "s3_input_train = sagemaker.s3_input(s3_data=train_location, content_type='csv')\n",
    "\n",
    "xgb.fit({'train': s3_input_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................\u001b[34mArguments: serve\u001b[0m\n",
      "\u001b[34m[2020-08-01 23:17:59 +0000] [1] [INFO] Starting gunicorn 19.7.1\u001b[0m\n",
      "\u001b[34m[2020-08-01 23:17:59 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2020-08-01 23:17:59 +0000] [1] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2020-08-01 23:17:59 +0000] [37] [INFO] Booting worker with pid: 37\u001b[0m\n",
      "\u001b[34m[2020-08-01 23:17:59 +0000] [38] [INFO] Booting worker with pid: 38\u001b[0m\n",
      "\u001b[34m[2020-08-01 23:17:59 +0000] [39] [INFO] Booting worker with pid: 39\u001b[0m\n",
      "\u001b[34m[2020-08-01 23:17:59 +0000] [40] [INFO] Booting worker with pid: 40\u001b[0m\n",
      "\u001b[34m[2020-08-01:23:17:59:INFO] Model loaded successfully for worker : 37\u001b[0m\n",
      "\u001b[34m[2020-08-01:23:17:59:INFO] Model loaded successfully for worker : 38\u001b[0m\n",
      "\u001b[34m[2020-08-01:23:17:59:INFO] Model loaded successfully for worker : 40\u001b[0m\n",
      "\u001b[34m[2020-08-01:23:17:59:INFO] Model loaded successfully for worker : 39\u001b[0m\n",
      "\n",
      "\u001b[34m[2020-08-01:23:18:07:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2020-08-01:23:18:07:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2020-08-01:23:18:07:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[35m[2020-08-01:23:18:07:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[32m2020-08-01T23:18:07.086:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "xgb_transformer = xgb.transformer(instance_count = 1, instance_type = 'ml.m4.xlarge')\n",
    "xgb_transformer.transform(test_location, content_type='text/csv', split_type='Line')\n",
    "xgb_transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 256.0 KiB/334.6 KiB (2.7 MiB/s) with 1 file(s) remaining\r",
      "Completed 334.6 KiB/334.6 KiB (3.5 MiB/s) with 1 file(s) remaining\r",
      "download: s3://sagemaker-us-east-2-290062341908/xgboost-2020-08-01-23-14-46-219/test_x.csv.out to data/test_x.csv.out\r\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp --recursive $xgb_transformer.output_path $\"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.read_csv(\"data/test_x.csv.out\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [round(num) for num in predictions.squeeze().values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7213773815766474"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(test_y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6820584422060436"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(test_y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7160378193928134"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(test_y, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training PyTorch Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = \"starbucks-pytorch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using PyTorch\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "output_path = f\"s3://{bucket}/{prefix}\"\n",
    "\n",
    "# instantiate a pytorch estimator\n",
    "estimator = PyTorch(entry_point=\"train.py\", source_dir=\"pytorch\",\n",
    "    role=role, framework_version=\"1.0\", train_instance_count=1,\n",
    "    train_instance_type=\"ml.p2.xlarge\", output_path=output_path,\n",
    "    sagemaker_session=sagemaker_session, \n",
    "    hyperparameters={\n",
    "        \"input_features\": 19,\n",
    "        \"hidden_dim\": 30, \n",
    "        \"output_dim\": 1,\n",
    "        \"epochs\": 100\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n",
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-01 23:32:59 Starting - Starting the training job...\n",
      "2020-08-01 23:33:01 Starting - Launching requested ML instances......\n",
      "2020-08-01 23:34:03 Starting - Preparing the instances for training.........\n",
      "2020-08-01 23:35:53 Downloading - Downloading input data\n",
      "2020-08-01 23:35:53 Training - Downloading the training image......\n",
      "2020-08-01 23:36:52 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-08-01 23:36:53,876 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-08-01 23:36:53,902 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-08-01 23:36:56,919 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-08-01 23:36:57,157 sagemaker-containers INFO     Module train does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-08-01 23:36:57,157 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-08-01 23:36:57,157 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-08-01 23:36:57,157 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m pip install -U . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: train\n",
      "  Running setup.py bdist_wheel for train: started\n",
      "  Running setup.py bdist_wheel for train: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-gk1n14sz/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\u001b[0m\n",
      "\u001b[34mSuccessfully built train\u001b[0m\n",
      "\u001b[34mInstalling collected packages: train\u001b[0m\n",
      "\u001b[34mSuccessfully installed train-1.0.0\u001b[0m\n",
      "\u001b[34mYou are using pip version 18.1, however version 20.2 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-08-01 23:36:59,296 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"hidden_dim\": 30,\n",
      "        \"input_features\": 19,\n",
      "        \"epochs\": 100,\n",
      "        \"output_dim\": 1\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"ContentType\": \"csv\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-pytorch-2020-08-01-23-32-59-248\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-290062341908/sagemaker-pytorch-2020-08-01-23-32-59-248/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":100,\"hidden_dim\":30,\"input_features\":19,\"output_dim\":1}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"ContentType\":\"csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-290062341908/sagemaker-pytorch-2020-08-01-23-32-59-248/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":100,\"hidden_dim\":30,\"input_features\":19,\"output_dim\":1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"ContentType\":\"csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-pytorch-2020-08-01-23-32-59-248\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-290062341908/sagemaker-pytorch-2020-08-01-23-32-59-248/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"100\",\"--hidden_dim\",\"30\",\"--input_features\",\"19\",\"--output_dim\",\"1\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_HIDDEN_DIM=30\u001b[0m\n",
      "\u001b[34mSM_HP_INPUT_FEATURES=19\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=100\u001b[0m\n",
      "\u001b[34mSM_HP_OUTPUT_DIM=1\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m train --epochs 100 --hidden_dim 30 --input_features 19 --output_dim 1\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mUsing device cuda.\u001b[0m\n",
      "\u001b[34mGet train data loader.\u001b[0m\n",
      "\u001b[34mEpoch: 1, Loss: 0.6054155537865582\u001b[0m\n",
      "\u001b[34mEpoch: 2, Loss: 0.5870486026650734\u001b[0m\n",
      "\u001b[34mEpoch: 3, Loss: 0.581682058153081\u001b[0m\n",
      "\u001b[34mEpoch: 4, Loss: 0.5791457639428114\u001b[0m\n",
      "\u001b[34mEpoch: 5, Loss: 0.5749435779167695\u001b[0m\n",
      "\u001b[34mEpoch: 6, Loss: 0.572332920008496\u001b[0m\n",
      "\u001b[34mEpoch: 7, Loss: 0.570201491394293\u001b[0m\n",
      "\u001b[34mEpoch: 8, Loss: 0.5697601545839274\u001b[0m\n",
      "\u001b[34mEpoch: 9, Loss: 0.5681976142168491\u001b[0m\n",
      "\u001b[34mEpoch: 10, Loss: 0.5681598344852639\u001b[0m\n",
      "\u001b[34mEpoch: 11, Loss: 0.5675416671604699\u001b[0m\n",
      "\u001b[34mEpoch: 12, Loss: 0.5672186966859892\u001b[0m\n",
      "\u001b[34mEpoch: 13, Loss: 0.566606353817696\u001b[0m\n",
      "\u001b[34mEpoch: 14, Loss: 0.567497343634175\u001b[0m\n",
      "\u001b[34mEpoch: 15, Loss: 0.5674978568647685\u001b[0m\n",
      "\u001b[34mEpoch: 16, Loss: 0.5678522855350364\u001b[0m\n",
      "\u001b[34mEpoch: 17, Loss: 0.5659921270798655\u001b[0m\n",
      "\u001b[34mEpoch: 18, Loss: 0.5669660880296641\u001b[0m\n",
      "\u001b[34mEpoch: 19, Loss: 0.5650936586552122\u001b[0m\n",
      "\u001b[34mEpoch: 20, Loss: 0.5656897135553288\u001b[0m\n",
      "\u001b[34mEpoch: 21, Loss: 0.5649396325206936\u001b[0m\n",
      "\u001b[34mEpoch: 22, Loss: 0.5657595584120196\u001b[0m\n",
      "\u001b[34mEpoch: 23, Loss: 0.5662069800417968\u001b[0m\n",
      "\u001b[34mEpoch: 24, Loss: 0.5650622090736355\u001b[0m\n",
      "\u001b[34mEpoch: 25, Loss: 0.5643355411369256\u001b[0m\n",
      "\u001b[34mEpoch: 26, Loss: 0.5652355726905977\u001b[0m\n",
      "\u001b[34mEpoch: 27, Loss: 0.5649853869295969\u001b[0m\n",
      "\u001b[34mEpoch: 28, Loss: 0.5664029768678579\u001b[0m\n",
      "\u001b[34mEpoch: 29, Loss: 0.5650012893958039\u001b[0m\n",
      "\u001b[34mEpoch: 30, Loss: 0.5649138729419377\u001b[0m\n",
      "\u001b[34mEpoch: 31, Loss: 0.5649078816761461\u001b[0m\n",
      "\u001b[34mEpoch: 32, Loss: 0.5641995545713866\u001b[0m\n",
      "\u001b[34mEpoch: 33, Loss: 0.5655332339055529\u001b[0m\n",
      "\u001b[34mEpoch: 34, Loss: 0.5654470641347353\u001b[0m\n",
      "\u001b[34mEpoch: 35, Loss: 0.563927732583847\u001b[0m\n",
      "\u001b[34mEpoch: 36, Loss: 0.5649137814337395\u001b[0m\n",
      "\u001b[34mEpoch: 37, Loss: 0.5644710598562317\u001b[0m\n",
      "\u001b[34mEpoch: 38, Loss: 0.5645737535079544\u001b[0m\n",
      "\u001b[34mEpoch: 39, Loss: 0.5646827206880636\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mEpoch: 40, Loss: 0.5631655686915144\u001b[0m\n",
      "\u001b[34mEpoch: 41, Loss: 0.5640585910124278\u001b[0m\n",
      "\u001b[34mEpoch: 42, Loss: 0.5634665642115061\u001b[0m\n",
      "\u001b[34mEpoch: 43, Loss: 0.5641576561058282\u001b[0m\n",
      "\u001b[34mEpoch: 44, Loss: 0.5647241723169102\u001b[0m\n",
      "\u001b[34mEpoch: 45, Loss: 0.5642444735218524\u001b[0m\n",
      "\u001b[34mEpoch: 46, Loss: 0.564201508747058\u001b[0m\n",
      "\u001b[34mEpoch: 47, Loss: 0.5630445745386434\u001b[0m\n",
      "\u001b[34mEpoch: 48, Loss: 0.5628977005819926\u001b[0m\n",
      "\u001b[34mEpoch: 49, Loss: 0.5636496361554338\u001b[0m\n",
      "\u001b[34mEpoch: 50, Loss: 0.563911111465889\u001b[0m\n",
      "\u001b[34mEpoch: 51, Loss: 0.5636467011875651\u001b[0m\n",
      "\u001b[34mEpoch: 52, Loss: 0.5637597518941659\u001b[0m\n",
      "\u001b[34mEpoch: 53, Loss: 0.564462282115154\u001b[0m\n",
      "\u001b[34mEpoch: 54, Loss: 0.5628810370766492\u001b[0m\n",
      "\u001b[34mEpoch: 55, Loss: 0.5635869333220556\u001b[0m\n",
      "\u001b[34mEpoch: 56, Loss: 0.5632949665049265\u001b[0m\n",
      "\u001b[34mEpoch: 57, Loss: 0.5626511592404003\u001b[0m\n",
      "\u001b[34mEpoch: 58, Loss: 0.5637366153104475\u001b[0m\n",
      "\u001b[34mEpoch: 59, Loss: 0.563914757104737\u001b[0m\n",
      "\u001b[34mEpoch: 60, Loss: 0.5633158057286275\u001b[0m\n",
      "\u001b[34mEpoch: 61, Loss: 0.5631143637308467\u001b[0m\n",
      "\u001b[34mEpoch: 62, Loss: 0.5633649985776858\u001b[0m\n",
      "\u001b[34mEpoch: 63, Loss: 0.5636755887963129\u001b[0m\n",
      "\u001b[34mEpoch: 64, Loss: 0.563419999687301\u001b[0m\n",
      "\u001b[34mEpoch: 65, Loss: 0.5632121113160353\u001b[0m\n",
      "\u001b[34mEpoch: 66, Loss: 0.5641047578430578\u001b[0m\n",
      "\u001b[34mEpoch: 67, Loss: 0.563935890012466\u001b[0m\n",
      "\u001b[34mEpoch: 68, Loss: 0.5637387432437041\u001b[0m\n",
      "\u001b[34mEpoch: 69, Loss: 0.5635281457631999\u001b[0m\n",
      "\u001b[34mEpoch: 70, Loss: 0.5626904528183437\u001b[0m\n",
      "\u001b[34mEpoch: 71, Loss: 0.5636751503673162\u001b[0m\n",
      "\u001b[34mEpoch: 72, Loss: 0.5637189847755522\u001b[0m\n",
      "\u001b[34mEpoch: 73, Loss: 0.5630937403842304\u001b[0m\n",
      "\u001b[34mEpoch: 74, Loss: 0.5636398294528995\u001b[0m\n",
      "\u001b[34mEpoch: 75, Loss: 0.5635343501909396\u001b[0m\n",
      "\u001b[34mEpoch: 76, Loss: 0.563413399937894\u001b[0m\n",
      "\u001b[34mEpoch: 77, Loss: 0.5629590286660507\u001b[0m\n",
      "\u001b[34mEpoch: 78, Loss: 0.5631804455448403\u001b[0m\n",
      "\u001b[34mEpoch: 79, Loss: 0.5624705899716094\u001b[0m\n",
      "\u001b[34mEpoch: 80, Loss: 0.5634242803388544\u001b[0m\n",
      "\u001b[34mEpoch: 81, Loss: 0.5629733087669374\u001b[0m\n",
      "\u001b[34mEpoch: 82, Loss: 0.5627617352826988\u001b[0m\n",
      "\u001b[34mEpoch: 83, Loss: 0.5635165752654665\u001b[0m\n",
      "\u001b[34mEpoch: 84, Loss: 0.5620836436246218\u001b[0m\n",
      "\u001b[34mEpoch: 85, Loss: 0.5621884865037511\u001b[0m\n",
      "\u001b[34mEpoch: 86, Loss: 0.562387727876281\u001b[0m\n",
      "\u001b[34mEpoch: 87, Loss: 0.5622411860285627\u001b[0m\n",
      "\u001b[34mEpoch: 88, Loss: 0.5620675649228837\u001b[0m\n",
      "\u001b[34mEpoch: 89, Loss: 0.5631293605971203\u001b[0m\n",
      "\u001b[34mEpoch: 90, Loss: 0.5633294747033146\u001b[0m\n",
      "\u001b[34mEpoch: 91, Loss: 0.5620078609147099\u001b[0m\n",
      "\u001b[34mEpoch: 92, Loss: 0.562368047485749\u001b[0m\n",
      "\u001b[34mEpoch: 93, Loss: 0.5622956564670868\u001b[0m\n",
      "\u001b[34mEpoch: 94, Loss: 0.5628676260901747\u001b[0m\n",
      "\u001b[34mEpoch: 95, Loss: 0.5624824098963639\u001b[0m\n",
      "\u001b[34mEpoch: 96, Loss: 0.5623410906991485\u001b[0m\n",
      "\u001b[34mEpoch: 97, Loss: 0.5627718480282955\u001b[0m\n",
      "\u001b[34mEpoch: 98, Loss: 0.562110596127836\u001b[0m\n",
      "\u001b[34mEpoch: 99, Loss: 0.5626274875877948\u001b[0m\n",
      "\u001b[34mEpoch: 100, Loss: 0.5623728963375538\u001b[0m\n",
      "\u001b[34m2020-08-01 23:50:45,018 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-08-01 23:50:53 Uploading - Uploading generated training model\n",
      "2020-08-01 23:50:53 Completed - Training job completed\n",
      "Training seconds: 919\n",
      "Billable seconds: 919\n"
     ]
    }
   ],
   "source": [
    "estimator.fit({'train': s3_input_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "# Deploy the trained PyTorch model\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "\n",
    "model = PyTorchModel(\n",
    "    entry_point=\"predict.py\",\n",
    "    role=role, \n",
    "    framework_version=\"1.0\",\n",
    "    model_data=estimator.model_data,\n",
    "    source_dir=\"pytorch\"\n",
    ")\n",
    "\n",
    "# deploy your model to create a predictor\n",
    "predictor = model.deploy(initial_instance_count=1, instance_type=\"ml.t2.medium\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:10: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n"
     ]
    }
   ],
   "source": [
    "# evaluating the model\n",
    "# read in test data, assuming it is stored locally\n",
    "test_data = pd.read_csv(\"data/test_full.csv\", header=None, names=None)\n",
    "\n",
    "# labels are in the first column\n",
    "test_y = test_data.iloc[:,0]\n",
    "test_x = test_data.iloc[:,1:]\n",
    "test_y_preds = np.hstack(\n",
    "    predictor.predict(test_x.iloc[i: i+1000]).reshape(1, -1).squeeze() \n",
    "    for i in range(0, len(test_x), 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7213773815766474"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(test_y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:3: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6766610485537375"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the test roc_auc_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(test_y, np.hstack([i.reshape(1, -1).squeeze()] for i in test_y_preds).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lower hidden dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n",
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-02 04:23:27 Starting - Starting the training job...\n",
      "2020-08-02 04:23:29 Starting - Launching requested ML instances......\n",
      "2020-08-02 04:24:31 Starting - Preparing the instances for training......\n",
      "2020-08-02 04:25:56 Downloading - Downloading input data...\n",
      "2020-08-02 04:26:20 Training - Downloading the training image......\n",
      "2020-08-02 04:27:16 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-08-02 04:27:17,382 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-08-02 04:27:17,411 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-08-02 04:27:18,870 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-08-02 04:27:19,112 sagemaker-containers INFO     Module train does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-08-02 04:27:19,112 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-08-02 04:27:19,112 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-08-02 04:27:19,113 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m pip install -U . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: train\n",
      "  Running setup.py bdist_wheel for train: started\n",
      "  Running setup.py bdist_wheel for train: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-dsu0lltg/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\u001b[0m\n",
      "\u001b[34mSuccessfully built train\u001b[0m\n",
      "\u001b[34mInstalling collected packages: train\u001b[0m\n",
      "\u001b[34mSuccessfully installed train-1.0.0\u001b[0m\n",
      "\u001b[34mYou are using pip version 18.1, however version 20.2 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-08-02 04:27:21,336 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"hidden_dim\": 15,\n",
      "        \"input_features\": 19,\n",
      "        \"epochs\": 100,\n",
      "        \"output_dim\": 1\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"ContentType\": \"csv\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-pytorch-2020-08-02-04-23-26-979\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-290062341908/sagemaker-pytorch-2020-08-02-04-23-26-979/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":100,\"hidden_dim\":15,\"input_features\":19,\"output_dim\":1}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"ContentType\":\"csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-290062341908/sagemaker-pytorch-2020-08-02-04-23-26-979/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":100,\"hidden_dim\":15,\"input_features\":19,\"output_dim\":1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"ContentType\":\"csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-pytorch-2020-08-02-04-23-26-979\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-290062341908/sagemaker-pytorch-2020-08-02-04-23-26-979/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"100\",\"--hidden_dim\",\"15\",\"--input_features\",\"19\",\"--output_dim\",\"1\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_HIDDEN_DIM=15\u001b[0m\n",
      "\u001b[34mSM_HP_INPUT_FEATURES=19\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=100\u001b[0m\n",
      "\u001b[34mSM_HP_OUTPUT_DIM=1\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m train --epochs 100 --hidden_dim 15 --input_features 19 --output_dim 1\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mUsing device cuda.\u001b[0m\n",
      "\u001b[34mGet train data loader.\u001b[0m\n",
      "\u001b[34mEpoch: 1, Loss: 0.6087145946054869\u001b[0m\n",
      "\u001b[34mEpoch: 2, Loss: 0.5916479199343406\u001b[0m\n",
      "\u001b[34mEpoch: 3, Loss: 0.5871407820323433\u001b[0m\n",
      "\u001b[34mEpoch: 4, Loss: 0.583472649451722\u001b[0m\n",
      "\u001b[34mEpoch: 5, Loss: 0.5807515254069804\u001b[0m\n",
      "\u001b[34mEpoch: 6, Loss: 0.5773878853586729\u001b[0m\n",
      "\u001b[34mEpoch: 7, Loss: 0.5774795892728625\u001b[0m\n",
      "\u001b[34mEpoch: 8, Loss: 0.5763144051342198\u001b[0m\n",
      "\u001b[34mEpoch: 9, Loss: 0.5743937578066235\u001b[0m\n",
      "\u001b[34mEpoch: 10, Loss: 0.5736594121945038\u001b[0m\n",
      "\u001b[34mEpoch: 11, Loss: 0.5725669285303421\u001b[0m\n",
      "\u001b[34mEpoch: 12, Loss: 0.5744714893791336\u001b[0m\n",
      "\u001b[34mEpoch: 13, Loss: 0.5717325505804033\u001b[0m\n",
      "\u001b[34mEpoch: 14, Loss: 0.5718671049908752\u001b[0m\n",
      "\u001b[34mEpoch: 15, Loss: 0.5716604465793135\u001b[0m\n",
      "\u001b[34mEpoch: 16, Loss: 0.5713121950012467\u001b[0m\n",
      "\u001b[34mEpoch: 17, Loss: 0.5718004499621382\u001b[0m\n",
      "\u001b[34mEpoch: 18, Loss: 0.5717425021255731\u001b[0m\n",
      "\u001b[34mEpoch: 19, Loss: 0.5706400117261357\u001b[0m\n",
      "\u001b[34mEpoch: 20, Loss: 0.571137677590722\u001b[0m\n",
      "\u001b[34mEpoch: 21, Loss: 0.571593999636642\u001b[0m\n",
      "\u001b[34mEpoch: 22, Loss: 0.5703507133525856\u001b[0m\n",
      "\u001b[34mEpoch: 23, Loss: 0.5717963682215536\u001b[0m\n",
      "\u001b[34mEpoch: 24, Loss: 0.5709333725441038\u001b[0m\n",
      "\u001b[34mEpoch: 25, Loss: 0.5707772452872567\u001b[0m\n",
      "\u001b[34mEpoch: 26, Loss: 0.5717644663255537\u001b[0m\n",
      "\u001b[34mEpoch: 27, Loss: 0.5703279831854815\u001b[0m\n",
      "\u001b[34mEpoch: 28, Loss: 0.5716571873939885\u001b[0m\n",
      "\u001b[34mEpoch: 29, Loss: 0.5707222476908553\u001b[0m\n",
      "\u001b[34mEpoch: 30, Loss: 0.5718417755757155\u001b[0m\n",
      "\u001b[34mEpoch: 31, Loss: 0.569214812289463\u001b[0m\n",
      "\u001b[34mEpoch: 32, Loss: 0.56976222274232\u001b[0m\n",
      "\u001b[34mEpoch: 33, Loss: 0.5708622068138828\u001b[0m\n",
      "\u001b[34mEpoch: 34, Loss: 0.5705325562186009\u001b[0m\n",
      "\u001b[34mEpoch: 35, Loss: 0.5699373635655262\u001b[0m\n",
      "\u001b[34mEpoch: 36, Loss: 0.5704204036027528\u001b[0m\n",
      "\u001b[34mEpoch: 37, Loss: 0.5703670814075273\u001b[0m\n",
      "\u001b[34mEpoch: 38, Loss: 0.5691112965987193\u001b[0m\n",
      "\u001b[34mEpoch: 39, Loss: 0.5692387688221333\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mEpoch: 40, Loss: 0.5691882857418016\u001b[0m\n",
      "\u001b[34mEpoch: 41, Loss: 0.5697584757699948\u001b[0m\n",
      "\u001b[34mEpoch: 42, Loss: 0.5689942342204771\u001b[0m\n",
      "\u001b[34mEpoch: 43, Loss: 0.5702198976434572\u001b[0m\n",
      "\u001b[34mEpoch: 44, Loss: 0.5688601532651021\u001b[0m\n",
      "\u001b[34mEpoch: 45, Loss: 0.5697743418204427\u001b[0m\n",
      "\u001b[34mEpoch: 46, Loss: 0.5707387903461072\u001b[0m\n",
      "\u001b[34mEpoch: 47, Loss: 0.5702929901914874\u001b[0m\n",
      "\u001b[34mEpoch: 48, Loss: 0.5697801967182856\u001b[0m\n",
      "\u001b[34mEpoch: 49, Loss: 0.5690218874577726\u001b[0m\n",
      "\u001b[34mEpoch: 50, Loss: 0.5699533915279733\u001b[0m\n",
      "\u001b[34mEpoch: 51, Loss: 0.5698173541868671\u001b[0m\n",
      "\u001b[34mEpoch: 52, Loss: 0.5696064603351029\u001b[0m\n",
      "\u001b[34mEpoch: 53, Loss: 0.5690010259018632\u001b[0m\n",
      "\u001b[34mEpoch: 54, Loss: 0.5700222345885266\u001b[0m\n",
      "\u001b[34mEpoch: 55, Loss: 0.5692665423793293\u001b[0m\n",
      "\u001b[34mEpoch: 56, Loss: 0.5698742443200354\u001b[0m\n",
      "\u001b[34mEpoch: 57, Loss: 0.5693693534321106\u001b[0m\n",
      "\u001b[34mEpoch: 58, Loss: 0.5701889367976438\u001b[0m\n",
      "\u001b[34mEpoch: 59, Loss: 0.5700939099133461\u001b[0m\n",
      "\u001b[34mEpoch: 60, Loss: 0.569752828146188\u001b[0m\n",
      "\u001b[34mEpoch: 61, Loss: 0.5697249274575309\u001b[0m\n",
      "\u001b[34mEpoch: 62, Loss: 0.5694402349547724\u001b[0m\n",
      "\u001b[34mEpoch: 63, Loss: 0.568466367176298\u001b[0m\n",
      "\u001b[34mEpoch: 64, Loss: 0.5693105741135414\u001b[0m\n",
      "\u001b[34mEpoch: 65, Loss: 0.5699430717511124\u001b[0m\n",
      "\u001b[34mEpoch: 66, Loss: 0.5693739241344875\u001b[0m\n",
      "\u001b[34mEpoch: 67, Loss: 0.5694988371281141\u001b[0m\n",
      "\u001b[34mEpoch: 68, Loss: 0.5687190462922336\u001b[0m\n",
      "\u001b[34mEpoch: 69, Loss: 0.5680128943579696\u001b[0m\n",
      "\u001b[34mEpoch: 70, Loss: 0.5695178661955876\u001b[0m\n",
      "\u001b[34mEpoch: 71, Loss: 0.5682703239333987\u001b[0m\n",
      "\u001b[34mEpoch: 72, Loss: 0.5690832169314896\u001b[0m\n",
      "\u001b[34mEpoch: 73, Loss: 0.5687930547649718\u001b[0m\n",
      "\u001b[34mEpoch: 74, Loss: 0.5696323352667053\u001b[0m\n",
      "\u001b[34mEpoch: 75, Loss: 0.5694136597885845\u001b[0m\n",
      "\u001b[34mEpoch: 76, Loss: 0.5694376686371667\u001b[0m\n",
      "\u001b[34mEpoch: 77, Loss: 0.568262006208468\u001b[0m\n",
      "\u001b[34mEpoch: 78, Loss: 0.5690388207132003\u001b[0m\n",
      "\u001b[34mEpoch: 79, Loss: 0.5687183627419258\u001b[0m\n",
      "\u001b[34mEpoch: 80, Loss: 0.5696411250682359\u001b[0m\n",
      "\u001b[34mEpoch: 81, Loss: 0.5680415477533912\u001b[0m\n",
      "\u001b[34mEpoch: 82, Loss: 0.568856508237369\u001b[0m\n",
      "\u001b[34mEpoch: 83, Loss: 0.5688408354973972\u001b[0m\n",
      "\u001b[34mEpoch: 84, Loss: 0.5697707021476401\u001b[0m\n",
      "\u001b[34mEpoch: 85, Loss: 0.570426782767536\u001b[0m\n",
      "\u001b[34mEpoch: 86, Loss: 0.5698735128153353\u001b[0m\n",
      "\u001b[34mEpoch: 87, Loss: 0.5685637349632572\u001b[0m\n",
      "\u001b[34mEpoch: 88, Loss: 0.5690142797871253\u001b[0m\n",
      "\u001b[34mEpoch: 89, Loss: 0.5676091013943658\u001b[0m\n",
      "\u001b[34mEpoch: 90, Loss: 0.569656437456831\u001b[0m\n",
      "\u001b[34mEpoch: 91, Loss: 0.569293840600645\u001b[0m\n",
      "\u001b[34mEpoch: 92, Loss: 0.567894071468923\u001b[0m\n",
      "\u001b[34mEpoch: 93, Loss: 0.5695196697048927\u001b[0m\n",
      "\u001b[34mEpoch: 94, Loss: 0.5686195561892531\u001b[0m\n",
      "\u001b[34mEpoch: 95, Loss: 0.567301718419076\u001b[0m\n",
      "\u001b[34mEpoch: 96, Loss: 0.5687768963615546\u001b[0m\n",
      "\u001b[34mEpoch: 97, Loss: 0.5683504295204016\u001b[0m\n",
      "\u001b[34mEpoch: 98, Loss: 0.5694325066628527\u001b[0m\n",
      "\u001b[34mEpoch: 99, Loss: 0.5692571619616242\u001b[0m\n",
      "\u001b[34mEpoch: 100, Loss: 0.5691829183993491\u001b[0m\n",
      "\u001b[34m2020-08-02 04:41:26,884 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-08-02 04:42:33 Uploading - Uploading generated training model\n",
      "2020-08-02 04:42:33 Completed - Training job completed\n",
      "Training seconds: 997\n",
      "Billable seconds: 997\n"
     ]
    }
   ],
   "source": [
    "# specify an output path\n",
    "output_path = f\"s3://{bucket}/{prefix}-lower-hidden-dim\"\n",
    "\n",
    "# instantiate a pytorch estimator\n",
    "estimator = PyTorch(\n",
    "    entry_point=\"train.py\",\n",
    "    source_dir=\"pytorch\",\n",
    "    role=role,\n",
    "    framework_version=\"1.0\",\n",
    "    train_instance_count=1,\n",
    "    train_instance_type=\"ml.p2.xlarge\", # \"ml.c4.xlarge\",\n",
    "    output_path=output_path,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    hyperparameters={\n",
    "        \"input_features\": 19,\n",
    "        \"hidden_dim\": 15, \n",
    "        \"output_dim\": 1,\n",
    "        \"epochs\": 100\n",
    "    })\n",
    "estimator.fit({'train': s3_input_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    }
   ],
   "source": [
    "# Deploy the trained model\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "model = PyTorchModel(\n",
    "    entry_point=\"predict.py\",\n",
    "    role=role, \n",
    "    framework_version=\"1.0\",\n",
    "    model_data=estimator.model_data,\n",
    "    source_dir=\"pytorch\"\n",
    ")\n",
    "\n",
    "# deploy your model to create a predictor\n",
    "predictor = model.deploy(initial_instance_count=1, instance_type=\"ml.t2.medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:10: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n"
     ]
    }
   ],
   "source": [
    "# evaluating the model\n",
    "# read in test data, assuming it is stored locally\n",
    "test_data = pd.read_csv(\"data/test_full.csv\", header=None, names=None)\n",
    "\n",
    "# labels are in the first column\n",
    "test_y = test_data.iloc[:,0]\n",
    "test_x = test_data.iloc[:,1:]\n",
    "test_y_preds = np.hstack(\n",
    "    predictor.predict(test_x.iloc[i: i+1000]).reshape(1, -1).squeeze() \n",
    "    for i in range(0, len(test_x), 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6783056209109046"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the test roc_auc_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(test_y, test_y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6709928334207307"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(test_y, test_y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6795488401787614"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(test_y, test_y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Higher epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n",
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-02 05:21:19 Starting - Starting the training job...\n",
      "2020-08-02 05:21:21 Starting - Launching requested ML instances......\n",
      "2020-08-02 05:22:25 Starting - Preparing the instances for training...\n",
      "2020-08-02 05:23:11 Downloading - Downloading input data...\n",
      "2020-08-02 05:23:47 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-08-02 05:23:48,771 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-08-02 05:23:48,774 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-08-02 05:23:48,786 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-08-02 05:23:50,210 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-08-02 05:23:50,451 sagemaker-containers INFO     Module train does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-08-02 05:23:50,451 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-08-02 05:23:50,451 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-08-02 05:23:50,451 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m pip install -U . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: train\n",
      "  Running setup.py bdist_wheel for train: started\n",
      "  Running setup.py bdist_wheel for train: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-wg5hp7pi/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\u001b[0m\n",
      "\u001b[34mSuccessfully built train\u001b[0m\n",
      "\u001b[34mInstalling collected packages: train\u001b[0m\n",
      "\u001b[34mSuccessfully installed train-1.0.0\u001b[0m\n",
      "\u001b[34mYou are using pip version 18.1, however version 20.2 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-08-02 05:23:52,096 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-08-02 05:23:52,108 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"hidden_dim\": 15,\n",
      "        \"input_features\": 19,\n",
      "        \"epochs\": 200,\n",
      "        \"output_dim\": 1\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"ContentType\": \"csv\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-pytorch-2020-08-02-05-21-19-691\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-290062341908/sagemaker-pytorch-2020-08-02-05-21-19-691/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":200,\"hidden_dim\":15,\"input_features\":19,\"output_dim\":1}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"ContentType\":\"csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-290062341908/sagemaker-pytorch-2020-08-02-05-21-19-691/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":200,\"hidden_dim\":15,\"input_features\":19,\"output_dim\":1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"ContentType\":\"csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-pytorch-2020-08-02-05-21-19-691\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-290062341908/sagemaker-pytorch-2020-08-02-05-21-19-691/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"200\",\"--hidden_dim\",\"15\",\"--input_features\",\"19\",\"--output_dim\",\"1\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_HIDDEN_DIM=15\u001b[0m\n",
      "\u001b[34mSM_HP_INPUT_FEATURES=19\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=200\u001b[0m\n",
      "\u001b[34mSM_HP_OUTPUT_DIM=1\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m train --epochs 200 --hidden_dim 15 --input_features 19 --output_dim 1\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mUsing device cpu.\u001b[0m\n",
      "\u001b[34mGet train data loader.\u001b[0m\n",
      "\u001b[34mEpoch: 1, Loss: 0.609901526190815\u001b[0m\n",
      "\u001b[34mEpoch: 2, Loss: 0.5909948701492409\u001b[0m\n",
      "\u001b[34mEpoch: 3, Loss: 0.5868728632421306\u001b[0m\n",
      "\u001b[34mEpoch: 4, Loss: 0.58408088154449\u001b[0m\n",
      "\u001b[34mEpoch: 5, Loss: 0.5803169117856785\u001b[0m\n",
      "\u001b[34mEpoch: 6, Loss: 0.5781046684147714\u001b[0m\n",
      "\u001b[34mEpoch: 7, Loss: 0.5770949833932217\u001b[0m\n",
      "\u001b[34mEpoch: 8, Loss: 0.5769078972494781\u001b[0m\n",
      "\u001b[34mEpoch: 9, Loss: 0.5752799734222085\u001b[0m\n",
      "\u001b[34mEpoch: 10, Loss: 0.5744303676045119\u001b[0m\n",
      "\u001b[34mEpoch: 11, Loss: 0.5751311368793808\u001b[0m\n",
      "\u001b[34mEpoch: 12, Loss: 0.5723845337102476\u001b[0m\n",
      "\u001b[34mEpoch: 13, Loss: 0.573112613208285\u001b[0m\n",
      "\u001b[34mEpoch: 14, Loss: 0.5725221196670881\u001b[0m\n",
      "\u001b[34mEpoch: 15, Loss: 0.5727326554082306\u001b[0m\n",
      "\u001b[34mEpoch: 16, Loss: 0.5728350456455227\u001b[0m\n",
      "\u001b[34mEpoch: 17, Loss: 0.5719746583940162\u001b[0m\n",
      "\u001b[34mEpoch: 18, Loss: 0.5725064250971941\u001b[0m\n",
      "\u001b[34mEpoch: 19, Loss: 0.5725922198108073\u001b[0m\n",
      "\u001b[34mEpoch: 20, Loss: 0.5717340085920546\u001b[0m\n",
      "\u001b[34mEpoch: 21, Loss: 0.5724343960344345\u001b[0m\n",
      "\u001b[34mEpoch: 22, Loss: 0.5727788836154598\u001b[0m\n",
      "\u001b[34mEpoch: 23, Loss: 0.5711431733398848\u001b[0m\n",
      "\u001b[34mEpoch: 24, Loss: 0.5713099734418178\u001b[0m\n",
      "\u001b[34mEpoch: 25, Loss: 0.5724429964544845\u001b[0m\n",
      "\u001b[34mEpoch: 26, Loss: 0.5712434250205644\u001b[0m\n",
      "\u001b[34mEpoch: 27, Loss: 0.5710360545260407\u001b[0m\n",
      "\u001b[34mEpoch: 28, Loss: 0.5709535086199585\u001b[0m\n",
      "\u001b[34mEpoch: 29, Loss: 0.5706514493244864\u001b[0m\n",
      "\u001b[34mEpoch: 30, Loss: 0.5712022936466928\u001b[0m\n",
      "\u001b[34mEpoch: 31, Loss: 0.5713473950404576\u001b[0m\n",
      "\u001b[34mEpoch: 32, Loss: 0.5721050194614612\u001b[0m\n",
      "\u001b[34mEpoch: 33, Loss: 0.5701527173627405\u001b[0m\n",
      "\u001b[34mEpoch: 34, Loss: 0.5714574619457963\u001b[0m\n",
      "\u001b[34mEpoch: 35, Loss: 0.5710239034718119\u001b[0m\n",
      "\u001b[34mEpoch: 36, Loss: 0.5711014479845204\u001b[0m\n",
      "\u001b[34mEpoch: 37, Loss: 0.5718942484242863\u001b[0m\n",
      "\u001b[34mEpoch: 38, Loss: 0.5710573067546784\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mEpoch: 39, Loss: 0.5710417843350534\u001b[0m\n",
      "\u001b[34mEpoch: 40, Loss: 0.570806183155333\u001b[0m\n",
      "\u001b[34mEpoch: 41, Loss: 0.5706702093450764\u001b[0m\n",
      "\u001b[34mEpoch: 42, Loss: 0.5696929525179363\u001b[0m\n",
      "\u001b[34mEpoch: 43, Loss: 0.5719858081934603\u001b[0m\n",
      "\u001b[34mEpoch: 44, Loss: 0.5699253421597713\u001b[0m\n",
      "\u001b[34mEpoch: 45, Loss: 0.5705500151278374\u001b[0m\n",
      "\u001b[34mEpoch: 46, Loss: 0.5703532095454382\u001b[0m\n",
      "\u001b[34mEpoch: 47, Loss: 0.5706414050405169\u001b[0m\n",
      "\u001b[34mEpoch: 48, Loss: 0.5696726559727603\u001b[0m\n",
      "\u001b[34mEpoch: 49, Loss: 0.569334594280309\u001b[0m\n",
      "\u001b[34mEpoch: 50, Loss: 0.5703028764980339\u001b[0m\n",
      "\u001b[34mEpoch: 51, Loss: 0.5703907062972753\u001b[0m\n",
      "\u001b[34mEpoch: 52, Loss: 0.5698256547810433\u001b[0m\n",
      "\u001b[34mEpoch: 53, Loss: 0.5708259495903044\u001b[0m\n",
      "\u001b[34mEpoch: 54, Loss: 0.5704331443746214\u001b[0m\n",
      "\u001b[34mEpoch: 55, Loss: 0.56993686201309\u001b[0m\n",
      "\u001b[34mEpoch: 56, Loss: 0.5719337852567099\u001b[0m\n",
      "\u001b[34mEpoch: 57, Loss: 0.5685718259170707\u001b[0m\n",
      "\u001b[34mEpoch: 58, Loss: 0.5704483584267147\u001b[0m\n",
      "\u001b[34mEpoch: 59, Loss: 0.5708758233247625\u001b[0m\n",
      "\u001b[34mEpoch: 60, Loss: 0.5703394589966603\u001b[0m\n",
      "\u001b[34mEpoch: 61, Loss: 0.5692874966628766\u001b[0m\n",
      "\u001b[34mEpoch: 62, Loss: 0.5692042834470781\u001b[0m\n",
      "\u001b[34mEpoch: 63, Loss: 0.5712606833054779\u001b[0m\n",
      "\u001b[34mEpoch: 64, Loss: 0.5703451147993629\u001b[0m\n",
      "\u001b[34mEpoch: 65, Loss: 0.5705255122750663\u001b[0m\n",
      "\u001b[34mEpoch: 66, Loss: 0.5693927068444673\u001b[0m\n",
      "\u001b[34mEpoch: 67, Loss: 0.5705887962007121\u001b[0m\n",
      "\u001b[34mEpoch: 68, Loss: 0.5699772166011485\u001b[0m\n",
      "\u001b[34mEpoch: 69, Loss: 0.5702909166642119\u001b[0m\n",
      "\u001b[34mEpoch: 70, Loss: 0.5706120668837193\u001b[0m\n",
      "\u001b[34mEpoch: 71, Loss: 0.5712482603413336\u001b[0m\n",
      "\u001b[34mEpoch: 72, Loss: 0.5719479965555311\u001b[0m\n",
      "\u001b[34mEpoch: 73, Loss: 0.5699910586804486\u001b[0m\n",
      "\u001b[34mEpoch: 74, Loss: 0.5694740523783008\u001b[0m\n",
      "\u001b[34mEpoch: 75, Loss: 0.5703379312341803\u001b[0m\n",
      "\u001b[34mEpoch: 76, Loss: 0.5697901768491286\u001b[0m\n",
      "\u001b[34mEpoch: 77, Loss: 0.5695039053869605\u001b[0m\n",
      "\u001b[34mEpoch: 78, Loss: 0.5675437916307413\u001b[0m\n",
      "\u001b[34mEpoch: 79, Loss: 0.5706196463677321\u001b[0m\n",
      "\u001b[34mEpoch: 80, Loss: 0.5690494876954886\u001b[0m\n",
      "\u001b[34mEpoch: 81, Loss: 0.5698108152922396\u001b[0m\n",
      "\u001b[34mEpoch: 82, Loss: 0.5700590316275979\u001b[0m\n",
      "\u001b[34mEpoch: 83, Loss: 0.5684279128797491\u001b[0m\n",
      "\u001b[34mEpoch: 84, Loss: 0.5695969217306889\u001b[0m\n",
      "\u001b[34mEpoch: 85, Loss: 0.5698864030871499\u001b[0m\n",
      "\u001b[34mEpoch: 86, Loss: 0.5695202425178071\u001b[0m\n",
      "\u001b[34mEpoch: 87, Loss: 0.5688302350178194\u001b[0m\n",
      "\u001b[34mEpoch: 88, Loss: 0.569360266380319\u001b[0m\n",
      "\u001b[34mEpoch: 89, Loss: 0.570352486947949\u001b[0m\n",
      "\u001b[34mEpoch: 90, Loss: 0.5693995612781593\u001b[0m\n",
      "\u001b[34mEpoch: 91, Loss: 0.5704644116513738\u001b[0m\n",
      "\u001b[34mEpoch: 92, Loss: 0.5688976464283824\u001b[0m\n",
      "\u001b[34mEpoch: 93, Loss: 0.570338654992509\u001b[0m\n",
      "\u001b[34mEpoch: 94, Loss: 0.5711749787550517\u001b[0m\n",
      "\u001b[34mEpoch: 95, Loss: 0.5689479736129889\u001b[0m\n",
      "\u001b[34mEpoch: 96, Loss: 0.5692656186970879\u001b[0m\n",
      "\u001b[34mEpoch: 97, Loss: 0.5695680157550042\u001b[0m\n",
      "\u001b[34mEpoch: 98, Loss: 0.5700826071732946\u001b[0m\n",
      "\u001b[34mEpoch: 99, Loss: 0.5692223228988577\u001b[0m\n",
      "\u001b[34mEpoch: 100, Loss: 0.5704809948690375\u001b[0m\n",
      "\u001b[34mEpoch: 101, Loss: 0.5690126572153095\u001b[0m\n",
      "\u001b[34mEpoch: 102, Loss: 0.569662729349364\u001b[0m\n",
      "\u001b[34mEpoch: 103, Loss: 0.5691166846214162\u001b[0m\n",
      "\u001b[34mEpoch: 104, Loss: 0.5693446679173337\u001b[0m\n",
      "\u001b[34mEpoch: 105, Loss: 0.5697326274121298\u001b[0m\n",
      "\u001b[34mEpoch: 106, Loss: 0.5695079959845275\u001b[0m\n",
      "\u001b[34mEpoch: 107, Loss: 0.5702263397865751\u001b[0m\n",
      "\u001b[34mEpoch: 108, Loss: 0.5698361215603709\u001b[0m\n",
      "\u001b[34mEpoch: 109, Loss: 0.5685222910947344\u001b[0m\n",
      "\u001b[34mEpoch: 110, Loss: 0.5699125404410371\u001b[0m\n",
      "\u001b[34mEpoch: 111, Loss: 0.5682242723523677\u001b[0m\n",
      "\u001b[34mEpoch: 112, Loss: 0.5694493366789058\u001b[0m\n",
      "\u001b[34mEpoch: 113, Loss: 0.5701217585763012\u001b[0m\n",
      "\u001b[34mEpoch: 114, Loss: 0.5695736182065269\u001b[0m\n",
      "\u001b[34mEpoch: 115, Loss: 0.5688459967573484\u001b[0m\n",
      "\u001b[34mEpoch: 116, Loss: 0.5700950676805517\u001b[0m\n",
      "\u001b[34mEpoch: 117, Loss: 0.5694264380058992\u001b[0m\n",
      "\u001b[34mEpoch: 118, Loss: 0.5701407307096188\u001b[0m\n",
      "\u001b[34mEpoch: 119, Loss: 0.5696915954351425\u001b[0m\n",
      "\u001b[34mEpoch: 120, Loss: 0.5705995772801312\u001b[0m\n",
      "\u001b[34mEpoch: 121, Loss: 0.5696032883131995\u001b[0m\n",
      "\u001b[34mEpoch: 122, Loss: 0.5690331314554375\u001b[0m\n",
      "\u001b[34mEpoch: 123, Loss: 0.5703893424726827\u001b[0m\n",
      "\u001b[34mEpoch: 124, Loss: 0.5684613611535186\u001b[0m\n",
      "\u001b[34mEpoch: 125, Loss: 0.569033877024155\u001b[0m\n",
      "\u001b[34mEpoch: 126, Loss: 0.5684130553672376\u001b[0m\n",
      "\u001b[34mEpoch: 127, Loss: 0.5702103622118185\u001b[0m\n",
      "\u001b[34mEpoch: 128, Loss: 0.5677674357001478\u001b[0m\n",
      "\u001b[34mEpoch: 129, Loss: 0.5688738864766302\u001b[0m\n",
      "\u001b[34mEpoch: 130, Loss: 0.570192891521177\u001b[0m\n",
      "\u001b[34mEpoch: 131, Loss: 0.5698591714773732\u001b[0m\n",
      "\u001b[34mEpoch: 132, Loss: 0.5693588893204816\u001b[0m\n",
      "\u001b[34mEpoch: 133, Loss: 0.5701597421273087\u001b[0m\n",
      "\u001b[34mEpoch: 134, Loss: 0.5693448359293214\u001b[0m\n",
      "\u001b[34mEpoch: 135, Loss: 0.5685598422916195\u001b[0m\n",
      "\u001b[34mEpoch: 136, Loss: 0.5700396326011263\u001b[0m\n",
      "\u001b[34mEpoch: 137, Loss: 0.5671454273722368\u001b[0m\n",
      "\u001b[34mEpoch: 138, Loss: 0.570068765911605\u001b[0m\n",
      "\u001b[34mEpoch: 139, Loss: 0.5690653449475542\u001b[0m\n",
      "\u001b[34mEpoch: 140, Loss: 0.5691098838932952\u001b[0m\n",
      "\u001b[34mEpoch: 141, Loss: 0.5691592506283009\u001b[0m\n",
      "\u001b[34mEpoch: 142, Loss: 0.5698219043959616\u001b[0m\n",
      "\u001b[34mEpoch: 143, Loss: 0.5684326022947103\u001b[0m\n",
      "\u001b[34mEpoch: 144, Loss: 0.5676451550050174\u001b[0m\n",
      "\u001b[34mEpoch: 145, Loss: 0.5690520055899013\u001b[0m\n",
      "\u001b[34mEpoch: 146, Loss: 0.5675159252035931\u001b[0m\n",
      "\u001b[34mEpoch: 147, Loss: 0.569388718451007\u001b[0m\n",
      "\u001b[34mEpoch: 148, Loss: 0.5684958043086171\u001b[0m\n",
      "\u001b[34mEpoch: 149, Loss: 0.5693649693877063\u001b[0m\n",
      "\u001b[34mEpoch: 150, Loss: 0.5691499875642164\u001b[0m\n",
      "\u001b[34mEpoch: 151, Loss: 0.5697367647167448\u001b[0m\n",
      "\u001b[34mEpoch: 152, Loss: 0.5689374301429099\u001b[0m\n",
      "\u001b[34mEpoch: 153, Loss: 0.5683137499019224\u001b[0m\n",
      "\u001b[34mEpoch: 154, Loss: 0.5688609621944499\u001b[0m\n",
      "\u001b[34mEpoch: 155, Loss: 0.5689014148622863\u001b[0m\n",
      "\u001b[34mEpoch: 156, Loss: 0.5697076444126917\u001b[0m\n",
      "\u001b[34mEpoch: 157, Loss: 0.5700641009803122\u001b[0m\n",
      "\u001b[34mEpoch: 158, Loss: 0.5689513564053993\u001b[0m\n",
      "\u001b[34mEpoch: 159, Loss: 0.5686004979305723\u001b[0m\n",
      "\u001b[34mEpoch: 160, Loss: 0.568350193443035\u001b[0m\n",
      "\u001b[34mEpoch: 161, Loss: 0.5689234208469087\u001b[0m\n",
      "\u001b[34mEpoch: 162, Loss: 0.569175061449576\u001b[0m\n",
      "\u001b[34mEpoch: 163, Loss: 0.5681622053465146\u001b[0m\n",
      "\u001b[34mEpoch: 164, Loss: 0.5686167604412032\u001b[0m\n",
      "\u001b[34mEpoch: 165, Loss: 0.5685167210546326\u001b[0m\n",
      "\u001b[34mEpoch: 166, Loss: 0.5705307928447643\u001b[0m\n",
      "\u001b[34mEpoch: 167, Loss: 0.5695414108590463\u001b[0m\n",
      "\u001b[34mEpoch: 168, Loss: 0.5685839822927441\u001b[0m\n",
      "\u001b[34mEpoch: 169, Loss: 0.5681465059825767\u001b[0m\n",
      "\u001b[34mEpoch: 170, Loss: 0.5690455404085836\u001b[0m\n",
      "\u001b[34mEpoch: 171, Loss: 0.5679555629271916\u001b[0m\n",
      "\u001b[34mEpoch: 172, Loss: 0.5694865490697073\u001b[0m\n",
      "\u001b[34mEpoch: 173, Loss: 0.5695069354125176\u001b[0m\n",
      "\u001b[34mEpoch: 174, Loss: 0.5684617171377948\u001b[0m\n",
      "\u001b[34mEpoch: 175, Loss: 0.5689671844913718\u001b[0m\n",
      "\u001b[34mEpoch: 176, Loss: 0.5698733581362592\u001b[0m\n",
      "\u001b[34mEpoch: 177, Loss: 0.5686384844618121\u001b[0m\n",
      "\u001b[34mEpoch: 178, Loss: 0.5680133288105329\u001b[0m\n",
      "\u001b[34mEpoch: 179, Loss: 0.5689656033386452\u001b[0m\n",
      "\u001b[34mEpoch: 180, Loss: 0.5683253593798657\u001b[0m\n",
      "\u001b[34mEpoch: 181, Loss: 0.568826318872667\u001b[0m\n",
      "\u001b[34mEpoch: 182, Loss: 0.5691696927621124\u001b[0m\n",
      "\u001b[34mEpoch: 183, Loss: 0.5688007798338874\u001b[0m\n",
      "\u001b[34mEpoch: 184, Loss: 0.5695583423341481\u001b[0m\n",
      "\u001b[34mEpoch: 185, Loss: 0.5688744283431255\u001b[0m\n",
      "\u001b[34mEpoch: 186, Loss: 0.5693831154720836\u001b[0m\n",
      "\u001b[34mEpoch: 187, Loss: 0.5682055003913155\u001b[0m\n",
      "\u001b[34mEpoch: 188, Loss: 0.5694612678879879\u001b[0m\n",
      "\u001b[34mEpoch: 189, Loss: 0.5688121158894751\u001b[0m\n",
      "\u001b[34mEpoch: 190, Loss: 0.5675287982525674\u001b[0m\n",
      "\u001b[34mEpoch: 191, Loss: 0.5683765785329128\u001b[0m\n",
      "\u001b[34mEpoch: 192, Loss: 0.569604578667254\u001b[0m\n",
      "\u001b[34mEpoch: 193, Loss: 0.5693020138066359\u001b[0m\n",
      "\u001b[34mEpoch: 194, Loss: 0.5679053785035226\u001b[0m\n",
      "\u001b[34mEpoch: 195, Loss: 0.5688179143387057\u001b[0m\n",
      "\u001b[34mEpoch: 196, Loss: 0.5687138793787706\u001b[0m\n",
      "\u001b[34mEpoch: 197, Loss: 0.5689643832963057\u001b[0m\n",
      "\u001b[34mEpoch: 198, Loss: 0.5687796858812539\u001b[0m\n",
      "\u001b[34mEpoch: 199, Loss: 0.5688739141916738\u001b[0m\n",
      "\u001b[34mEpoch: 200, Loss: 0.5690040454910266\u001b[0m\n",
      "\u001b[34m2020-08-02 05:35:33,184 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-08-02 05:35:40 Uploading - Uploading generated training model\n",
      "2020-08-02 05:35:40 Completed - Training job completed\n",
      "Training seconds: 749\n",
      "Billable seconds: 749\n"
     ]
    }
   ],
   "source": [
    "# import a PyTorch wrapper\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "# specify an output path\n",
    "output_path = f\"s3://{bucket}/{prefix}-higher-epochs\"\n",
    "\n",
    "# instantiate a pytorch estimator\n",
    "estimator = PyTorch(\n",
    "    entry_point=\"train.py\",\n",
    "    source_dir=\"pytorch\",\n",
    "    role=role,\n",
    "    framework_version=\"1.0\",\n",
    "    train_instance_count=1,\n",
    "    train_instance_type=\"ml.c4.xlarge\",\n",
    "    output_path=output_path,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    hyperparameters={\n",
    "        \"input_features\": 19,\n",
    "        \"hidden_dim\": 15, \n",
    "        \"output_dim\": 1,\n",
    "        \"epochs\": 200\n",
    "    })\n",
    "estimator.fit({'train': s3_input_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    }
   ],
   "source": [
    "# Deploy the trained model\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "model = PyTorchModel(\n",
    "    entry_point=\"predict.py\",\n",
    "    role=role, \n",
    "    framework_version=\"1.0\",\n",
    "    model_data=estimator.model_data,\n",
    "    source_dir=\"pytorch\"\n",
    ")\n",
    "\n",
    "# deploy your model to create a predictor\n",
    "predictor = model.deploy(initial_instance_count=1, instance_type=\"ml.t2.medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:10: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n"
     ]
    }
   ],
   "source": [
    "# evaluating the model\n",
    "# read in test data, assuming it is stored locally\n",
    "test_data = pd.read_csv(\"data/test_full.csv\", header=None, names=None)\n",
    "\n",
    "# labels are in the first column\n",
    "test_y = test_data.iloc[:,0]\n",
    "test_x = test_data.iloc[:,1:]\n",
    "test_y_preds = np.hstack(\n",
    "    predictor.predict(test_x.iloc[i: i+1000]).reshape(1, -1).squeeze() \n",
    "    for i in range(0, len(test_x), 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6748383149798987"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(test_y, test_y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6808218590485996"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(test_y, test_y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6814906957161151"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the test roc_auc_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(test_y, test_y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "An error occurred (ValidationException) when calling the DeleteEndpointConfig operation: Could not find endpoint configuration \"arn:aws:sagemaker:us-east-2:290062341908:endpoint-config/sagemaker-pytorch-2020-08-02-06-41-21-237\".",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-9dbbcf45efe1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/predictor.py\u001b[0m in \u001b[0;36mdelete_endpoint\u001b[0;34m(self, delete_endpoint_config)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \"\"\"\n\u001b[1;32m    175\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdelete_endpoint_config\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delete_endpoint_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/predictor.py\u001b[0m in \u001b[0;36m_delete_endpoint_config\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_delete_endpoint_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;34m\"\"\"Delete the Amazon SageMaker endpoint configuration\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete_endpoint_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_endpoint_config_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdelete_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelete_endpoint_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mdelete_endpoint_config\u001b[0;34m(self, endpoint_config_name)\u001b[0m\n\u001b[1;32m   2478\u001b[0m         \"\"\"\n\u001b[1;32m   2479\u001b[0m         \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Deleting endpoint configuration with name: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendpoint_config_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2480\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete_endpoint_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEndpointConfigName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mendpoint_config_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2482\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdelete_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    315\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (ValidationException) when calling the DeleteEndpointConfig operation: Could not find endpoint configuration \"arn:aws:sagemaker:us-east-2:290062341908:endpoint-config/sagemaker-pytorch-2020-08-02-06-41-21-237\"."
     ]
    }
   ],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6x hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n",
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-02 06:57:15 Starting - Starting the training job...\n",
      "2020-08-02 06:57:17 Starting - Launching requested ML instances.........\n",
      "2020-08-02 06:58:50 Starting - Preparing the instances for training...\n",
      "2020-08-02 06:59:42 Downloading - Downloading input data\n",
      "2020-08-02 06:59:42 Training - Downloading the training image..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-08-02 06:59:58,381 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-08-02 06:59:58,384 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-08-02 06:59:58,396 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-08-02 07:00:01,421 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-08-02 07:00:01,734 sagemaker-containers INFO     Module train does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-08-02 07:00:01,734 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-08-02 07:00:01,735 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-08-02 07:00:01,735 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m pip install -U . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: train\n",
      "  Running setup.py bdist_wheel for train: started\u001b[0m\n",
      "\n",
      "2020-08-02 06:59:57 Training - Training image download completed. Training in progress.\u001b[34m  Running setup.py bdist_wheel for train: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-p68mde_e/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\u001b[0m\n",
      "\u001b[34mSuccessfully built train\u001b[0m\n",
      "\u001b[34mInstalling collected packages: train\u001b[0m\n",
      "\u001b[34mSuccessfully installed train-1.0.0\u001b[0m\n",
      "\u001b[34mYou are using pip version 18.1, however version 20.2 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-08-02 07:00:03,483 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-08-02 07:00:03,495 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"hidden_dim\": 100,\n",
      "        \"input_features\": 19,\n",
      "        \"epochs\": 100,\n",
      "        \"output_dim\": 1\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"ContentType\": \"csv\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-pytorch-2020-08-02-06-57-15-019\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-290062341908/sagemaker-pytorch-2020-08-02-06-57-15-019/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":100,\"hidden_dim\":100,\"input_features\":19,\"output_dim\":1}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"ContentType\":\"csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-290062341908/sagemaker-pytorch-2020-08-02-06-57-15-019/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":100,\"hidden_dim\":100,\"input_features\":19,\"output_dim\":1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"ContentType\":\"csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-pytorch-2020-08-02-06-57-15-019\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-290062341908/sagemaker-pytorch-2020-08-02-06-57-15-019/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"100\",\"--hidden_dim\",\"100\",\"--input_features\",\"19\",\"--output_dim\",\"1\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_HIDDEN_DIM=100\u001b[0m\n",
      "\u001b[34mSM_HP_INPUT_FEATURES=19\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=100\u001b[0m\n",
      "\u001b[34mSM_HP_OUTPUT_DIM=1\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m train --epochs 100 --hidden_dim 100 --input_features 19 --output_dim 1\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mUsing device cpu.\u001b[0m\n",
      "\u001b[34mGet train data loader.\u001b[0m\n",
      "\u001b[34mEpoch: 1, Loss: 0.5954666713650307\u001b[0m\n",
      "\u001b[34mEpoch: 2, Loss: 0.5783249001405882\u001b[0m\n",
      "\u001b[34mEpoch: 3, Loss: 0.5705717450307772\u001b[0m\n",
      "\u001b[34mEpoch: 4, Loss: 0.5659854242947887\u001b[0m\n",
      "\u001b[34mEpoch: 5, Loss: 0.5639738978127415\u001b[0m\n",
      "\u001b[34mEpoch: 6, Loss: 0.5631271490080749\u001b[0m\n",
      "\u001b[34mEpoch: 7, Loss: 0.5624520914050077\u001b[0m\n",
      "\u001b[34mEpoch: 8, Loss: 0.5616953459655524\u001b[0m\n",
      "\u001b[34mEpoch: 9, Loss: 0.5613572015856089\u001b[0m\n",
      "\u001b[34mEpoch: 10, Loss: 0.5609245248641191\u001b[0m\n",
      "\u001b[34mEpoch: 11, Loss: 0.5604668365128701\u001b[0m\n",
      "\u001b[34mEpoch: 12, Loss: 0.5599023062275367\u001b[0m\n",
      "\u001b[34mEpoch: 13, Loss: 0.5613431989086255\u001b[0m\n",
      "\u001b[34mEpoch: 14, Loss: 0.5604870931151208\u001b[0m\n",
      "\u001b[34mEpoch: 15, Loss: 0.5601241729930322\u001b[0m\n",
      "\u001b[34mEpoch: 16, Loss: 0.559721741847666\u001b[0m\n",
      "\u001b[34mEpoch: 17, Loss: 0.5600540955080076\u001b[0m\n",
      "\u001b[34mEpoch: 18, Loss: 0.5587603016180939\u001b[0m\n",
      "\u001b[34mEpoch: 19, Loss: 0.5585090343536956\u001b[0m\n",
      "\u001b[34mEpoch: 20, Loss: 0.5594841141379281\u001b[0m\n",
      "\u001b[34mEpoch: 21, Loss: 0.5582344898849391\u001b[0m\n",
      "\u001b[34mEpoch: 22, Loss: 0.5584148555714986\u001b[0m\n",
      "\u001b[34mEpoch: 23, Loss: 0.5584100233872286\u001b[0m\n",
      "\u001b[34mEpoch: 24, Loss: 0.5580243113586741\u001b[0m\n",
      "\u001b[34mEpoch: 25, Loss: 0.5580241058482213\u001b[0m\n",
      "\u001b[34mEpoch: 26, Loss: 0.5569134563682008\u001b[0m\n",
      "\u001b[34mEpoch: 27, Loss: 0.5579760083824061\u001b[0m\n",
      "\u001b[34mEpoch: 28, Loss: 0.5582539064802704\u001b[0m\n",
      "\u001b[34mEpoch: 29, Loss: 0.5565620357512535\u001b[0m\n",
      "\u001b[34mEpoch: 30, Loss: 0.5571605262210529\u001b[0m\n",
      "\u001b[34mEpoch: 31, Loss: 0.5575683404555482\u001b[0m\n",
      "\u001b[34mEpoch: 32, Loss: 0.5560763382091282\u001b[0m\n",
      "\u001b[34mEpoch: 33, Loss: 0.5576119890541174\u001b[0m\n",
      "\u001b[34mEpoch: 34, Loss: 0.5576648181297359\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mEpoch: 35, Loss: 0.5565894423910741\u001b[0m\n",
      "\u001b[34mEpoch: 36, Loss: 0.5569022802991813\u001b[0m\n",
      "\u001b[34mEpoch: 37, Loss: 0.5560901731671242\u001b[0m\n",
      "\u001b[34mEpoch: 38, Loss: 0.5570221446231287\u001b[0m\n",
      "\u001b[34mEpoch: 39, Loss: 0.5564758293637622\u001b[0m\n",
      "\u001b[34mEpoch: 40, Loss: 0.5565909307491913\u001b[0m\n",
      "\u001b[34mEpoch: 41, Loss: 0.5567041448886029\u001b[0m\n",
      "\u001b[34mEpoch: 42, Loss: 0.5557181562684225\u001b[0m\n",
      "\u001b[34mEpoch: 43, Loss: 0.5563097157281883\u001b[0m\n",
      "\u001b[34mEpoch: 44, Loss: 0.5561630282341764\u001b[0m\n",
      "\u001b[34mEpoch: 45, Loss: 0.556248273173075\u001b[0m\n",
      "\u001b[34mEpoch: 46, Loss: 0.556177474893211\u001b[0m\n",
      "\u001b[34mEpoch: 47, Loss: 0.5558486906972048\u001b[0m\n",
      "\u001b[34mEpoch: 48, Loss: 0.5561224925858474\u001b[0m\n",
      "\u001b[34mEpoch: 49, Loss: 0.5560330238737418\u001b[0m\n",
      "\u001b[34mEpoch: 50, Loss: 0.5549440956768695\u001b[0m\n",
      "\u001b[34mEpoch: 51, Loss: 0.5556530242695121\u001b[0m\n",
      "\u001b[34mEpoch: 52, Loss: 0.5561214016896955\u001b[0m\n",
      "\u001b[34mEpoch: 53, Loss: 0.55566878280278\u001b[0m\n",
      "\u001b[34mEpoch: 54, Loss: 0.5556357022835298\u001b[0m\n",
      "\u001b[34mEpoch: 55, Loss: 0.5555755676206354\u001b[0m\n",
      "\u001b[34mEpoch: 56, Loss: 0.5554641690230772\u001b[0m\n",
      "\u001b[34mEpoch: 57, Loss: 0.5555509729610847\u001b[0m\n",
      "\u001b[34mEpoch: 58, Loss: 0.5559595439792349\u001b[0m\n",
      "\u001b[34mEpoch: 59, Loss: 0.554919367233354\u001b[0m\n",
      "\u001b[34mEpoch: 60, Loss: 0.5557441146493182\u001b[0m\n",
      "\u001b[34mEpoch: 61, Loss: 0.5560518335285928\u001b[0m\n",
      "\u001b[34mEpoch: 62, Loss: 0.5558382134870643\u001b[0m\n",
      "\u001b[34mEpoch: 63, Loss: 0.556001177151105\u001b[0m\n",
      "\u001b[34mEpoch: 64, Loss: 0.555436778408981\u001b[0m\n",
      "\u001b[34mEpoch: 65, Loss: 0.554581349398871\u001b[0m\n",
      "\u001b[34mEpoch: 66, Loss: 0.5554125146305516\u001b[0m\n",
      "\u001b[34mEpoch: 67, Loss: 0.5556641977796617\u001b[0m\n",
      "\u001b[34mEpoch: 68, Loss: 0.5553895411699006\u001b[0m\n",
      "\u001b[34mEpoch: 69, Loss: 0.5555027061047849\u001b[0m\n",
      "\u001b[34mEpoch: 70, Loss: 0.5557442036460848\u001b[0m\n",
      "\u001b[34mEpoch: 71, Loss: 0.555483014998811\u001b[0m\n",
      "\u001b[34mEpoch: 72, Loss: 0.5549639785306507\u001b[0m\n",
      "\u001b[34mEpoch: 73, Loss: 0.555310705834337\u001b[0m\n",
      "\u001b[34mEpoch: 74, Loss: 0.5552999415396528\u001b[0m\n",
      "\u001b[34mEpoch: 75, Loss: 0.5550273743238342\u001b[0m\n",
      "\u001b[34mEpoch: 76, Loss: 0.5548363627761268\u001b[0m\n",
      "\u001b[34mEpoch: 77, Loss: 0.5558469377011619\u001b[0m\n",
      "\u001b[34mEpoch: 78, Loss: 0.5544314707988657\u001b[0m\n",
      "\u001b[34mEpoch: 79, Loss: 0.5549075418839071\u001b[0m\n",
      "\u001b[34mEpoch: 80, Loss: 0.5546759731258346\u001b[0m\n",
      "\u001b[34mEpoch: 81, Loss: 0.5548901146494047\u001b[0m\n",
      "\u001b[34mEpoch: 82, Loss: 0.5540062449984113\u001b[0m\n",
      "\u001b[34mEpoch: 83, Loss: 0.5544417561774844\u001b[0m\n",
      "\u001b[34mEpoch: 84, Loss: 0.5544831969681081\u001b[0m\n",
      "\u001b[34mEpoch: 85, Loss: 0.5544266823023446\u001b[0m\n",
      "\u001b[34mEpoch: 86, Loss: 0.5542108164130525\u001b[0m\n",
      "\u001b[34mEpoch: 87, Loss: 0.5547155489300967\u001b[0m\n",
      "\u001b[34mEpoch: 88, Loss: 0.5547714980772596\u001b[0m\n",
      "\u001b[34mEpoch: 89, Loss: 0.5550192964015606\u001b[0m\n",
      "\u001b[34mEpoch: 90, Loss: 0.5544548129907039\u001b[0m\n",
      "\u001b[34mEpoch: 91, Loss: 0.5551430544770612\u001b[0m\n",
      "\u001b[34mEpoch: 92, Loss: 0.5544570870837022\u001b[0m\n",
      "\u001b[34mEpoch: 93, Loss: 0.5547669235463446\u001b[0m\n",
      "\u001b[34mEpoch: 94, Loss: 0.5543879724229767\u001b[0m\n",
      "\u001b[34mEpoch: 95, Loss: 0.5550244281800946\u001b[0m\n",
      "\u001b[34mEpoch: 96, Loss: 0.5549539921882001\u001b[0m\n",
      "\u001b[34mEpoch: 97, Loss: 0.5549231860661105\u001b[0m\n",
      "\u001b[34mEpoch: 98, Loss: 0.5553005534862534\u001b[0m\n",
      "\u001b[34mEpoch: 99, Loss: 0.5547549818450592\u001b[0m\n",
      "\u001b[34mEpoch: 100, Loss: 0.5539880444466622\u001b[0m\n",
      "\u001b[34m2020-08-02 07:06:47,745 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-08-02 07:06:57 Uploading - Uploading generated training model\n",
      "2020-08-02 07:06:57 Completed - Training job completed\n",
      "Training seconds: 453\n",
      "Billable seconds: 453\n"
     ]
    }
   ],
   "source": [
    "# import a PyTorch wrapper\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "# specify an output path\n",
    "output_path = f\"s3://{bucket}/{prefix}-5-hidden-layer\"\n",
    "\n",
    "# instantiate a pytorch estimator\n",
    "estimator = PyTorch(\n",
    "    entry_point=\"train.py\",\n",
    "    source_dir=\"pytorch\",\n",
    "    role=role,\n",
    "    framework_version=\"1.0\",\n",
    "    train_instance_count=1,\n",
    "    train_instance_type=\"ml.c4.xlarge\",\n",
    "    output_path=output_path,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    hyperparameters={\n",
    "        \"input_features\": 19,\n",
    "        \"hidden_dim\": 100, \n",
    "        \"output_dim\": 1,\n",
    "        \"epochs\": 100\n",
    "    })\n",
    "estimator.fit({'train': s3_input_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    }
   ],
   "source": [
    "# Deploy the trained model\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "model = PyTorchModel(\n",
    "    entry_point=\"predict.py\",\n",
    "    role=role, \n",
    "    framework_version=\"1.0\",\n",
    "    model_data=estimator.model_data,\n",
    "    source_dir=\"pytorch\"\n",
    ")\n",
    "\n",
    "# deploy your model to create a predictor\n",
    "predictor = model.deploy(initial_instance_count=1, instance_type=\"ml.t2.medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:10: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n"
     ]
    }
   ],
   "source": [
    "# evaluating the model\n",
    "# read in test data, assuming it is stored locally\n",
    "test_data = pd.read_csv(\"data/test_full.csv\", header=None, names=None)\n",
    "\n",
    "# labels are in the first column\n",
    "test_y = test_data.iloc[:,0]\n",
    "test_x = test_data.iloc[:,1:]\n",
    "test_y_preds = np.hstack(\n",
    "    predictor.predict(test_x.iloc[i: i+1000]).reshape(1, -1).squeeze() \n",
    "    for i in range(0, len(test_x), 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6580580318126201"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(test_y, test_y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6716461751500147"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(test_y, test_y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6665465522617937"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the test roc_auc_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(test_y, test_y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## no dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n",
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-02 07:26:06 Starting - Starting the training job...\n",
      "2020-08-02 07:26:07 Starting - Launching requested ML instances......\n",
      "2020-08-02 07:27:36 Starting - Preparing the instances for training.........\n",
      "2020-08-02 07:28:58 Downloading - Downloading input data\n",
      "2020-08-02 07:28:58 Training - Downloading the training image..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-08-02 07:29:14,695 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-08-02 07:29:14,698 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-08-02 07:29:14,711 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-08-02 07:29:14,712 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-08-02 07:29:14,961 sagemaker-containers INFO     Module train does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-08-02 07:29:14,961 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-08-02 07:29:14,961 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-08-02 07:29:14,961 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m pip install -U . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: train\n",
      "  Running setup.py bdist_wheel for train: started\n",
      "  Running setup.py bdist_wheel for train: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-u8j1dyo7/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\u001b[0m\n",
      "\u001b[34mSuccessfully built train\u001b[0m\n",
      "\u001b[34mInstalling collected packages: train\u001b[0m\n",
      "\u001b[34mSuccessfully installed train-1.0.0\u001b[0m\n",
      "\u001b[34mYou are using pip version 18.1, however version 20.2 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-08-02 07:29:16,826 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-08-02 07:29:16,839 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"hidden_dim\": 100,\n",
      "        \"input_features\": 19,\n",
      "        \"epochs\": 100,\n",
      "        \"output_dim\": 1\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"ContentType\": \"csv\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-pytorch-2020-08-02-07-26-05-857\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-290062341908/sagemaker-pytorch-2020-08-02-07-26-05-857/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":100,\"hidden_dim\":100,\"input_features\":19,\"output_dim\":1}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"ContentType\":\"csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-290062341908/sagemaker-pytorch-2020-08-02-07-26-05-857/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":100,\"hidden_dim\":100,\"input_features\":19,\"output_dim\":1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"ContentType\":\"csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-pytorch-2020-08-02-07-26-05-857\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-290062341908/sagemaker-pytorch-2020-08-02-07-26-05-857/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"100\",\"--hidden_dim\",\"100\",\"--input_features\",\"19\",\"--output_dim\",\"1\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_HIDDEN_DIM=100\u001b[0m\n",
      "\u001b[34mSM_HP_INPUT_FEATURES=19\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=100\u001b[0m\n",
      "\u001b[34mSM_HP_OUTPUT_DIM=1\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m train --epochs 100 --hidden_dim 100 --input_features 19 --output_dim 1\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mUsing device cpu.\u001b[0m\n",
      "\u001b[34mGet train data loader.\u001b[0m\n",
      "\u001b[34mEpoch: 1, Loss: 0.5954666713650307\u001b[0m\n",
      "\n",
      "2020-08-02 07:29:13 Training - Training image download completed. Training in progress.\u001b[34mEpoch: 2, Loss: 0.5783249001405882\u001b[0m\n",
      "\u001b[34mEpoch: 3, Loss: 0.5705717450307772\u001b[0m\n",
      "\u001b[34mEpoch: 4, Loss: 0.5659854242947887\u001b[0m\n",
      "\u001b[34mEpoch: 5, Loss: 0.5639738978127415\u001b[0m\n",
      "\u001b[34mEpoch: 6, Loss: 0.5631271490080749\u001b[0m\n",
      "\u001b[34mEpoch: 7, Loss: 0.5624520914050077\u001b[0m\n",
      "\u001b[34mEpoch: 8, Loss: 0.5616953459655524\u001b[0m\n",
      "\u001b[34mEpoch: 9, Loss: 0.5613572015856089\u001b[0m\n",
      "\u001b[34mEpoch: 10, Loss: 0.5609245248641191\u001b[0m\n",
      "\u001b[34mEpoch: 11, Loss: 0.5604668365128701\u001b[0m\n",
      "\u001b[34mEpoch: 12, Loss: 0.5599023062275367\u001b[0m\n",
      "\u001b[34mEpoch: 13, Loss: 0.5613431989086255\u001b[0m\n",
      "\u001b[34mEpoch: 14, Loss: 0.5604870931151208\u001b[0m\n",
      "\u001b[34mEpoch: 15, Loss: 0.5601241729930322\u001b[0m\n",
      "\u001b[34mEpoch: 16, Loss: 0.559721741847666\u001b[0m\n",
      "\u001b[34mEpoch: 17, Loss: 0.5600540955080076\u001b[0m\n",
      "\u001b[34mEpoch: 18, Loss: 0.5587603016180939\u001b[0m\n",
      "\u001b[34mEpoch: 19, Loss: 0.5585090343536956\u001b[0m\n",
      "\u001b[34mEpoch: 20, Loss: 0.5594841141379281\u001b[0m\n",
      "\u001b[34mEpoch: 21, Loss: 0.5582344898849391\u001b[0m\n",
      "\u001b[34mEpoch: 22, Loss: 0.5584148555714986\u001b[0m\n",
      "\u001b[34mEpoch: 23, Loss: 0.5584100233872286\u001b[0m\n",
      "\u001b[34mEpoch: 24, Loss: 0.5580243113586741\u001b[0m\n",
      "\u001b[34mEpoch: 25, Loss: 0.5580241058482213\u001b[0m\n",
      "\u001b[34mEpoch: 26, Loss: 0.5569134563682008\u001b[0m\n",
      "\u001b[34mEpoch: 27, Loss: 0.5579760083824061\u001b[0m\n",
      "\u001b[34mEpoch: 28, Loss: 0.5582539064802704\u001b[0m\n",
      "\u001b[34mEpoch: 29, Loss: 0.5565620357512535\u001b[0m\n",
      "\u001b[34mEpoch: 30, Loss: 0.5571605262210529\u001b[0m\n",
      "\u001b[34mEpoch: 31, Loss: 0.5575683404555482\u001b[0m\n",
      "\u001b[34mEpoch: 32, Loss: 0.5560763382091282\u001b[0m\n",
      "\u001b[34mEpoch: 33, Loss: 0.5576119890541174\u001b[0m\n",
      "\u001b[34mEpoch: 34, Loss: 0.5576648181297359\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mEpoch: 35, Loss: 0.5565894423910741\u001b[0m\n",
      "\u001b[34mEpoch: 36, Loss: 0.5569022802991813\u001b[0m\n",
      "\u001b[34mEpoch: 37, Loss: 0.5560901731671242\u001b[0m\n",
      "\u001b[34mEpoch: 38, Loss: 0.5570221446231287\u001b[0m\n",
      "\u001b[34mEpoch: 39, Loss: 0.5564758293637622\u001b[0m\n",
      "\u001b[34mEpoch: 40, Loss: 0.5565909307491913\u001b[0m\n",
      "\u001b[34mEpoch: 41, Loss: 0.5567041448886029\u001b[0m\n",
      "\u001b[34mEpoch: 42, Loss: 0.5557181562684225\u001b[0m\n",
      "\u001b[34mEpoch: 43, Loss: 0.5563097157281883\u001b[0m\n",
      "\u001b[34mEpoch: 44, Loss: 0.5561630282341764\u001b[0m\n",
      "\u001b[34mEpoch: 45, Loss: 0.556248273173075\u001b[0m\n",
      "\u001b[34mEpoch: 46, Loss: 0.556177474893211\u001b[0m\n",
      "\u001b[34mEpoch: 47, Loss: 0.5558486906972048\u001b[0m\n",
      "\u001b[34mEpoch: 48, Loss: 0.5561224925858474\u001b[0m\n",
      "\u001b[34mEpoch: 49, Loss: 0.5560330238737418\u001b[0m\n",
      "\u001b[34mEpoch: 50, Loss: 0.5549440956768695\u001b[0m\n",
      "\u001b[34mEpoch: 51, Loss: 0.5556530242695121\u001b[0m\n",
      "\u001b[34mEpoch: 52, Loss: 0.5561214016896955\u001b[0m\n",
      "\u001b[34mEpoch: 53, Loss: 0.55566878280278\u001b[0m\n",
      "\u001b[34mEpoch: 54, Loss: 0.5556357022835298\u001b[0m\n",
      "\u001b[34mEpoch: 55, Loss: 0.5555755676206354\u001b[0m\n",
      "\u001b[34mEpoch: 56, Loss: 0.5554641690230772\u001b[0m\n",
      "\u001b[34mEpoch: 57, Loss: 0.5555509729610847\u001b[0m\n",
      "\u001b[34mEpoch: 58, Loss: 0.5559595439792349\u001b[0m\n",
      "\u001b[34mEpoch: 59, Loss: 0.554919367233354\u001b[0m\n",
      "\u001b[34mEpoch: 60, Loss: 0.5557441146493182\u001b[0m\n",
      "\u001b[34mEpoch: 61, Loss: 0.5560518335285928\u001b[0m\n",
      "\u001b[34mEpoch: 62, Loss: 0.5558382134870643\u001b[0m\n",
      "\u001b[34mEpoch: 63, Loss: 0.556001177151105\u001b[0m\n",
      "\u001b[34mEpoch: 64, Loss: 0.555436778408981\u001b[0m\n",
      "\u001b[34mEpoch: 65, Loss: 0.554581349398871\u001b[0m\n",
      "\u001b[34mEpoch: 66, Loss: 0.5554125146305516\u001b[0m\n",
      "\u001b[34mEpoch: 67, Loss: 0.5556641977796617\u001b[0m\n",
      "\u001b[34mEpoch: 68, Loss: 0.5553895411699006\u001b[0m\n",
      "\u001b[34mEpoch: 69, Loss: 0.5555027061047849\u001b[0m\n",
      "\u001b[34mEpoch: 70, Loss: 0.5557442036460848\u001b[0m\n",
      "\u001b[34mEpoch: 71, Loss: 0.555483014998811\u001b[0m\n",
      "\u001b[34mEpoch: 72, Loss: 0.5549639785306507\u001b[0m\n",
      "\u001b[34mEpoch: 73, Loss: 0.555310705834337\u001b[0m\n",
      "\u001b[34mEpoch: 74, Loss: 0.5552999415396528\u001b[0m\n",
      "\u001b[34mEpoch: 75, Loss: 0.5550273743238342\u001b[0m\n",
      "\u001b[34mEpoch: 76, Loss: 0.5548363627761268\u001b[0m\n",
      "\u001b[34mEpoch: 77, Loss: 0.5558469377011619\u001b[0m\n",
      "\u001b[34mEpoch: 78, Loss: 0.5544314707988657\u001b[0m\n",
      "\u001b[34mEpoch: 79, Loss: 0.5549075418839071\u001b[0m\n",
      "\u001b[34mEpoch: 80, Loss: 0.5546759731258346\u001b[0m\n",
      "\u001b[34mEpoch: 81, Loss: 0.5548901146494047\u001b[0m\n",
      "\u001b[34mEpoch: 82, Loss: 0.5540062449984113\u001b[0m\n",
      "\u001b[34mEpoch: 83, Loss: 0.5544417561774844\u001b[0m\n",
      "\u001b[34mEpoch: 84, Loss: 0.5544831969681081\u001b[0m\n",
      "\u001b[34mEpoch: 85, Loss: 0.5544266823023446\u001b[0m\n",
      "\u001b[34mEpoch: 86, Loss: 0.5542108164130525\u001b[0m\n",
      "\u001b[34mEpoch: 87, Loss: 0.5547155489300967\u001b[0m\n",
      "\u001b[34mEpoch: 88, Loss: 0.5547714980772596\u001b[0m\n",
      "\u001b[34mEpoch: 89, Loss: 0.5550192964015606\u001b[0m\n",
      "\u001b[34mEpoch: 90, Loss: 0.5544548129907039\u001b[0m\n",
      "\u001b[34mEpoch: 91, Loss: 0.5551430544770612\u001b[0m\n",
      "\u001b[34mEpoch: 92, Loss: 0.5544570870837022\u001b[0m\n",
      "\u001b[34mEpoch: 93, Loss: 0.5547669235463446\u001b[0m\n",
      "\u001b[34mEpoch: 94, Loss: 0.5543879724229767\u001b[0m\n",
      "\u001b[34mEpoch: 95, Loss: 0.5550244281800946\u001b[0m\n",
      "\u001b[34mEpoch: 96, Loss: 0.5549539921882001\u001b[0m\n",
      "\u001b[34mEpoch: 97, Loss: 0.5549231860661105\u001b[0m\n",
      "\u001b[34mEpoch: 98, Loss: 0.5553005534862534\u001b[0m\n",
      "\n",
      "2020-08-02 07:36:07 Uploading - Uploading generated training model\u001b[34mEpoch: 99, Loss: 0.5547549818450592\u001b[0m\n",
      "\u001b[34mEpoch: 100, Loss: 0.5539880444466622\u001b[0m\n",
      "\u001b[34m2020-08-02 07:36:02,901 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-08-02 07:36:14 Completed - Training job completed\n",
      "Training seconds: 451\n",
      "Billable seconds: 451\n"
     ]
    }
   ],
   "source": [
    "# import a PyTorch wrapper\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "# specify an output path\n",
    "output_path = f\"s3://{bucket}/{prefix}-5-hidden-layer\"\n",
    "\n",
    "# instantiate a pytorch estimator\n",
    "estimator = PyTorch(\n",
    "    entry_point=\"train.py\",\n",
    "    source_dir=\"pytorch\",\n",
    "    role=role,\n",
    "    framework_version=\"1.0\",\n",
    "    train_instance_count=1,\n",
    "    train_instance_type=\"ml.c4.xlarge\",\n",
    "    output_path=output_path,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    hyperparameters={\n",
    "        \"input_features\": 19,\n",
    "        \"hidden_dim\": 100, \n",
    "        \"output_dim\": 1,\n",
    "        \"epochs\": 100\n",
    "    })\n",
    "estimator.fit({'train': s3_input_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    }
   ],
   "source": [
    "# Deploy the trained model\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "model = PyTorchModel(\n",
    "    entry_point=\"predict.py\",\n",
    "    role=role, \n",
    "    framework_version=\"1.0\",\n",
    "    model_data=estimator.model_data,\n",
    "    source_dir=\"pytorch\"\n",
    ")\n",
    "\n",
    "# deploy your model to create a predictor\n",
    "predictor = model.deploy(initial_instance_count=1, instance_type=\"ml.t2.medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:10: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n"
     ]
    }
   ],
   "source": [
    "# evaluating the model\n",
    "# read in test data, assuming it is stored locally\n",
    "test_data = pd.read_csv(\"data/test_full.csv\", header=None, names=None)\n",
    "\n",
    "# labels are in the first column\n",
    "test_y = test_data.iloc[:,0]\n",
    "test_x = test_data.iloc[:,1:]\n",
    "test_y_preds = np.hstack(\n",
    "    predictor.predict(test_x.iloc[i: i+1000]).reshape(1, -1).squeeze() \n",
    "    for i in range(0, len(test_x), 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6665465522617937"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the test roc_auc_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(test_y, test_y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6716461751500147"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(test_y, test_y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6580580318126201"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(test_y, test_y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 180,200, 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "s3_input_train = sagemaker.s3_input(s3_data=train_location, content_type='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n",
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-03 01:12:51 Starting - Starting the training job...\n",
      "2020-08-03 01:12:54 Starting - Launching requested ML instances.........\n",
      "2020-08-03 01:14:23 Starting - Preparing the instances for training...\n",
      "2020-08-03 01:15:16 Downloading - Downloading input data...\n",
      "2020-08-03 01:15:51 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-08-03 01:15:52,190 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-08-03 01:15:52,193 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-08-03 01:15:52,205 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-08-03 01:15:53,617 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-08-03 01:15:53,860 sagemaker-containers INFO     Module train does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-08-03 01:15:53,860 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-08-03 01:15:53,861 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-08-03 01:15:53,861 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m pip install -U . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: train\n",
      "  Running setup.py bdist_wheel for train: started\u001b[0m\n",
      "\u001b[34m  Running setup.py bdist_wheel for train: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-yanoaxbl/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\u001b[0m\n",
      "\u001b[34mSuccessfully built train\u001b[0m\n",
      "\u001b[34mInstalling collected packages: train\u001b[0m\n",
      "\u001b[34mSuccessfully installed train-1.0.0\u001b[0m\n",
      "\u001b[34mYou are using pip version 18.1, however version 20.2 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-08-03 01:15:55,489 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-08-03 01:15:55,501 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"hidden_dim\": 180,\n",
      "        \"input_features\": 19,\n",
      "        \"epochs\": 200,\n",
      "        \"output_dim\": 1\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"ContentType\": \"csv\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-pytorch-2020-08-03-01-12-50-997\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-290062341908/sagemaker-pytorch-2020-08-03-01-12-50-997/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":200,\"hidden_dim\":180,\"input_features\":19,\"output_dim\":1}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"ContentType\":\"csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-290062341908/sagemaker-pytorch-2020-08-03-01-12-50-997/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":200,\"hidden_dim\":180,\"input_features\":19,\"output_dim\":1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"ContentType\":\"csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-pytorch-2020-08-03-01-12-50-997\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-290062341908/sagemaker-pytorch-2020-08-03-01-12-50-997/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"200\",\"--hidden_dim\",\"180\",\"--input_features\",\"19\",\"--output_dim\",\"1\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_HIDDEN_DIM=180\u001b[0m\n",
      "\u001b[34mSM_HP_INPUT_FEATURES=19\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=200\u001b[0m\n",
      "\u001b[34mSM_HP_OUTPUT_DIM=1\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m train --epochs 200 --hidden_dim 180 --input_features 19 --output_dim 1\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mUsing device cpu.\u001b[0m\n",
      "\u001b[34mGet train data loader.\u001b[0m\n",
      "\u001b[34mEpoch: 1, Loss: 0.589762597366442\u001b[0m\n",
      "\u001b[34mEpoch: 2, Loss: 0.5735068681953328\u001b[0m\n",
      "\u001b[34mEpoch: 3, Loss: 0.5655855732352546\u001b[0m\n",
      "\u001b[34mEpoch: 4, Loss: 0.5622842028904497\u001b[0m\n",
      "\u001b[34mEpoch: 5, Loss: 0.5602717908217889\u001b[0m\n",
      "\u001b[34mEpoch: 6, Loss: 0.5592099753714233\u001b[0m\n",
      "\u001b[34mEpoch: 7, Loss: 0.5593170474279909\u001b[0m\n",
      "\u001b[34mEpoch: 8, Loss: 0.5584639970338746\u001b[0m\n",
      "\u001b[34mEpoch: 9, Loss: 0.5586862099639486\u001b[0m\n",
      "\u001b[34mEpoch: 10, Loss: 0.5578653999984488\u001b[0m\n",
      "\u001b[34mEpoch: 11, Loss: 0.5573163233027699\u001b[0m\n",
      "\u001b[34mEpoch: 12, Loss: 0.5575955509776703\u001b[0m\n",
      "\u001b[34mEpoch: 13, Loss: 0.557422734565391\u001b[0m\n",
      "\u001b[34mEpoch: 14, Loss: 0.556435019090381\u001b[0m\n",
      "\u001b[34mEpoch: 15, Loss: 0.5564909047318085\u001b[0m\n",
      "\u001b[34mEpoch: 16, Loss: 0.556154273196441\u001b[0m\n",
      "\u001b[34mEpoch: 17, Loss: 0.5557626011108191\u001b[0m\n",
      "\u001b[34mEpoch: 18, Loss: 0.5564791361965267\u001b[0m\n",
      "\u001b[34mEpoch: 19, Loss: 0.5559804486815403\u001b[0m\n",
      "\u001b[34mEpoch: 20, Loss: 0.5556273035091184\u001b[0m\n",
      "\u001b[34mEpoch: 21, Loss: 0.5551380937326044\u001b[0m\n",
      "\u001b[34mEpoch: 22, Loss: 0.5558504548914424\u001b[0m\n",
      "\u001b[34mEpoch: 23, Loss: 0.5549268215448222\u001b[0m\n",
      "\u001b[34mEpoch: 24, Loss: 0.5549158440351709\u001b[0m\n",
      "\u001b[34mEpoch: 25, Loss: 0.5545552992921197\u001b[0m\n",
      "\u001b[34mEpoch: 26, Loss: 0.5547253952769751\u001b[0m\n",
      "\u001b[34mEpoch: 27, Loss: 0.5543383786015297\u001b[0m\n",
      "\u001b[34mEpoch: 28, Loss: 0.5542449463982038\u001b[0m\n",
      "\u001b[34mEpoch: 29, Loss: 0.5540248762551095\u001b[0m\n",
      "\u001b[34mEpoch: 30, Loss: 0.553575224220083\u001b[0m\n",
      "\u001b[34mEpoch: 31, Loss: 0.5543197763295432\u001b[0m\n",
      "\u001b[34mEpoch: 32, Loss: 0.5541963873563635\u001b[0m\n",
      "\u001b[34mEpoch: 33, Loss: 0.5535003353398614\u001b[0m\n",
      "\u001b[34mEpoch: 34, Loss: 0.5535096177224362\u001b[0m\n",
      "\u001b[34mEpoch: 35, Loss: 0.5531678980655884\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mEpoch: 36, Loss: 0.5537568517531571\u001b[0m\n",
      "\u001b[34mEpoch: 37, Loss: 0.5529613730919718\u001b[0m\n",
      "\u001b[34mEpoch: 38, Loss: 0.5527754384117404\u001b[0m\n",
      "\u001b[34mEpoch: 39, Loss: 0.5531955315937264\u001b[0m\n",
      "\u001b[34mEpoch: 40, Loss: 0.5534251313028711\u001b[0m\n",
      "\u001b[34mEpoch: 41, Loss: 0.552926881296023\u001b[0m\n",
      "\u001b[34mEpoch: 42, Loss: 0.5538589406186498\u001b[0m\n",
      "\u001b[34mEpoch: 43, Loss: 0.5529311877539319\u001b[0m\n",
      "\u001b[34mEpoch: 44, Loss: 0.5524387712475289\u001b[0m\n",
      "\u001b[34mEpoch: 45, Loss: 0.5524474005323001\u001b[0m\n",
      "\u001b[34mEpoch: 46, Loss: 0.5531326096658403\u001b[0m\n",
      "\u001b[34mEpoch: 47, Loss: 0.553106377826313\u001b[0m\n",
      "\u001b[34mEpoch: 48, Loss: 0.5526186141126165\u001b[0m\n",
      "\u001b[34mEpoch: 49, Loss: 0.5532800063769916\u001b[0m\n",
      "\u001b[34mEpoch: 50, Loss: 0.5525659887029437\u001b[0m\n",
      "\u001b[34mEpoch: 51, Loss: 0.55296017392242\u001b[0m\n",
      "\u001b[34mEpoch: 52, Loss: 0.5532128064373459\u001b[0m\n",
      "\u001b[34mEpoch: 53, Loss: 0.5528453586002191\u001b[0m\n",
      "\u001b[34mEpoch: 54, Loss: 0.5518996891652823\u001b[0m\n",
      "\u001b[34mEpoch: 55, Loss: 0.5524170900496205\u001b[0m\n",
      "\u001b[34mEpoch: 56, Loss: 0.5527581418721417\u001b[0m\n",
      "\u001b[34mEpoch: 57, Loss: 0.55204646035694\u001b[0m\n",
      "\u001b[34mEpoch: 58, Loss: 0.552366188531288\u001b[0m\n",
      "\u001b[34mEpoch: 59, Loss: 0.5522369187422906\u001b[0m\n",
      "\u001b[34mEpoch: 60, Loss: 0.5522297721174773\u001b[0m\n",
      "\u001b[34mEpoch: 61, Loss: 0.5524517824140828\u001b[0m\n",
      "\u001b[34mEpoch: 62, Loss: 0.5524415688958954\u001b[0m\n",
      "\u001b[34mEpoch: 63, Loss: 0.5518801104849421\u001b[0m\n",
      "\u001b[34mEpoch: 64, Loss: 0.5517662000594737\u001b[0m\n",
      "\u001b[34mEpoch: 65, Loss: 0.5520967483966984\u001b[0m\n",
      "\u001b[34mEpoch: 66, Loss: 0.5528134056551849\u001b[0m\n",
      "\u001b[34mEpoch: 67, Loss: 0.5524631186287278\u001b[0m\n",
      "\u001b[34mEpoch: 68, Loss: 0.552099827824907\u001b[0m\n",
      "\u001b[34mEpoch: 69, Loss: 0.5522859737863032\u001b[0m\n",
      "\u001b[34mEpoch: 70, Loss: 0.5520553375032734\u001b[0m\n",
      "\u001b[34mEpoch: 71, Loss: 0.5521687295636657\u001b[0m\n",
      "\u001b[34mEpoch: 72, Loss: 0.551926282383083\u001b[0m\n",
      "\u001b[34mEpoch: 73, Loss: 0.5513824881964855\u001b[0m\n",
      "\u001b[34mEpoch: 74, Loss: 0.551828220609422\u001b[0m\n",
      "\u001b[34mEpoch: 75, Loss: 0.5521976138433714\u001b[0m\n",
      "\u001b[34mEpoch: 76, Loss: 0.5523786744598146\u001b[0m\n",
      "\u001b[34mEpoch: 77, Loss: 0.5517443861044972\u001b[0m\n",
      "\u001b[34mEpoch: 78, Loss: 0.5516724426927192\u001b[0m\n",
      "\u001b[34mEpoch: 79, Loss: 0.5516676189580214\u001b[0m\n",
      "\u001b[34mEpoch: 80, Loss: 0.5517930924948236\u001b[0m\n",
      "\u001b[34mEpoch: 81, Loss: 0.5522297848532263\u001b[0m\n",
      "\u001b[34mEpoch: 82, Loss: 0.5522917291282045\u001b[0m\n",
      "\u001b[34mEpoch: 83, Loss: 0.5518154631030471\u001b[0m\n",
      "\u001b[34mEpoch: 84, Loss: 0.5520937103010742\u001b[0m\n",
      "\u001b[34mEpoch: 85, Loss: 0.5521631403501784\u001b[0m\n",
      "\u001b[34mEpoch: 86, Loss: 0.551179447597109\u001b[0m\n",
      "\u001b[34mEpoch: 87, Loss: 0.5519471855813198\u001b[0m\n",
      "\u001b[34mEpoch: 88, Loss: 0.5520454224268818\u001b[0m\n",
      "\u001b[34mEpoch: 89, Loss: 0.5516266409544909\u001b[0m\n",
      "\u001b[34mEpoch: 90, Loss: 0.5515296860524778\u001b[0m\n",
      "\u001b[34mEpoch: 91, Loss: 0.5513119042868472\u001b[0m\n",
      "\u001b[34mEpoch: 92, Loss: 0.5519404368844818\u001b[0m\n",
      "\u001b[34mEpoch: 93, Loss: 0.5515553437843081\u001b[0m\n",
      "\u001b[34mEpoch: 94, Loss: 0.5516022911651081\u001b[0m\n",
      "\u001b[34mEpoch: 95, Loss: 0.5512956950967008\u001b[0m\n",
      "\u001b[34mEpoch: 96, Loss: 0.5515980126064145\u001b[0m\n",
      "\u001b[34mEpoch: 97, Loss: 0.5513245291952114\u001b[0m\n",
      "\u001b[34mEpoch: 98, Loss: 0.5515610542329733\u001b[0m\n",
      "\u001b[34mEpoch: 99, Loss: 0.5515316186605321\u001b[0m\n",
      "\u001b[34mEpoch: 100, Loss: 0.5518589548013183\u001b[0m\n",
      "\u001b[34mEpoch: 101, Loss: 0.5518964817349831\u001b[0m\n",
      "\u001b[34mEpoch: 102, Loss: 0.5514325028864409\u001b[0m\n",
      "\u001b[34mEpoch: 103, Loss: 0.5515272632045916\u001b[0m\n",
      "\u001b[34mEpoch: 104, Loss: 0.5518193324881323\u001b[0m\n",
      "\u001b[34mEpoch: 105, Loss: 0.5510732010146429\u001b[0m\n",
      "\u001b[34mEpoch: 106, Loss: 0.5506492507507962\u001b[0m\n",
      "\u001b[34mEpoch: 107, Loss: 0.5519579274098525\u001b[0m\n",
      "\u001b[34mEpoch: 108, Loss: 0.5507924245175128\u001b[0m\n",
      "\u001b[34mEpoch: 109, Loss: 0.5515341970888193\u001b[0m\n",
      "\u001b[34mEpoch: 110, Loss: 0.5509336674760343\u001b[0m\n",
      "\u001b[34mEpoch: 111, Loss: 0.5508419115835808\u001b[0m\n",
      "\u001b[34mEpoch: 112, Loss: 0.551741230152966\u001b[0m\n",
      "\u001b[34mEpoch: 113, Loss: 0.5514077743871159\u001b[0m\n",
      "\u001b[34mEpoch: 114, Loss: 0.5515477972530693\u001b[0m\n",
      "\u001b[34mEpoch: 115, Loss: 0.5510742285557454\u001b[0m\n",
      "\u001b[34mEpoch: 116, Loss: 0.5514213718446006\u001b[0m\n",
      "\u001b[34mEpoch: 117, Loss: 0.5515727320079054\u001b[0m\n",
      "\u001b[34mEpoch: 118, Loss: 0.5513746559647809\u001b[0m\n",
      "\u001b[34mEpoch: 119, Loss: 0.5513932499043951\u001b[0m\n",
      "\u001b[34mEpoch: 120, Loss: 0.5507814737378658\u001b[0m\n",
      "\u001b[34mEpoch: 121, Loss: 0.5511378381443157\u001b[0m\n",
      "\u001b[34mEpoch: 122, Loss: 0.5510854954967338\u001b[0m\n",
      "\u001b[34mEpoch: 123, Loss: 0.5509252180572083\u001b[0m\n",
      "\u001b[34mEpoch: 124, Loss: 0.5505495945305636\u001b[0m\n",
      "\u001b[34mEpoch: 125, Loss: 0.5506944763526488\u001b[0m\n",
      "\u001b[34mEpoch: 126, Loss: 0.5506578915462959\u001b[0m\n",
      "\u001b[34mEpoch: 127, Loss: 0.5511662851000546\u001b[0m\n",
      "\u001b[34mEpoch: 128, Loss: 0.5504808170713958\u001b[0m\n",
      "\u001b[34mEpoch: 129, Loss: 0.5510068334806502\u001b[0m\n",
      "\u001b[34mEpoch: 130, Loss: 0.5510459851906094\u001b[0m\n",
      "\u001b[34mEpoch: 131, Loss: 0.5505334655946114\u001b[0m\n",
      "\u001b[34mEpoch: 132, Loss: 0.5501993078836118\u001b[0m\n",
      "\u001b[34mEpoch: 133, Loss: 0.550906976580285\u001b[0m\n",
      "\u001b[34mEpoch: 134, Loss: 0.5508120348028253\u001b[0m\n",
      "\u001b[34mEpoch: 135, Loss: 0.5504878280398328\u001b[0m\n",
      "\u001b[34mEpoch: 136, Loss: 0.5507443195787932\u001b[0m\n",
      "\u001b[34mEpoch: 137, Loss: 0.5502163782632083\u001b[0m\n",
      "\u001b[34mEpoch: 138, Loss: 0.5505479807292254\u001b[0m\n",
      "\u001b[34mEpoch: 139, Loss: 0.5515100779800156\u001b[0m\n",
      "\u001b[34mEpoch: 140, Loss: 0.5507676646029681\u001b[0m\n",
      "\u001b[34mEpoch: 141, Loss: 0.5503991949535935\u001b[0m\n",
      "\u001b[34mEpoch: 142, Loss: 0.5504455413487966\u001b[0m\n",
      "\u001b[34mEpoch: 143, Loss: 0.5503779462939791\u001b[0m\n",
      "\u001b[34mEpoch: 144, Loss: 0.5506233921769853\u001b[0m\n",
      "\u001b[34mEpoch: 145, Loss: 0.5505621415287368\u001b[0m\n",
      "\u001b[34mEpoch: 146, Loss: 0.5501983615649997\u001b[0m\n",
      "\u001b[34mEpoch: 147, Loss: 0.5503013126775343\u001b[0m\n",
      "\u001b[34mEpoch: 148, Loss: 0.550535485131687\u001b[0m\n",
      "\u001b[34mEpoch: 149, Loss: 0.550509352130948\u001b[0m\n",
      "\u001b[34mEpoch: 150, Loss: 0.5501327624788668\u001b[0m\n",
      "\u001b[34mEpoch: 151, Loss: 0.5503917828230153\u001b[0m\n",
      "\u001b[34mEpoch: 152, Loss: 0.550821721626355\u001b[0m\n",
      "\u001b[34mEpoch: 153, Loss: 0.5504940937855717\u001b[0m\n",
      "\u001b[34mEpoch: 154, Loss: 0.5505628935881098\u001b[0m\n",
      "\u001b[34mEpoch: 155, Loss: 0.5503763976308067\u001b[0m\n",
      "\u001b[34mEpoch: 156, Loss: 0.551206229194608\u001b[0m\n",
      "\u001b[34mEpoch: 157, Loss: 0.5512066690160541\u001b[0m\n",
      "\u001b[34mEpoch: 158, Loss: 0.5501890658355607\u001b[0m\n",
      "\u001b[34mEpoch: 159, Loss: 0.5508952424376645\u001b[0m\n",
      "\u001b[34mEpoch: 160, Loss: 0.5505357662864615\u001b[0m\n",
      "\u001b[34mEpoch: 161, Loss: 0.5509191392456995\u001b[0m\n",
      "\u001b[34mEpoch: 162, Loss: 0.5511321736632215\u001b[0m\n",
      "\u001b[34mEpoch: 163, Loss: 0.5508579021033723\u001b[0m\n",
      "\u001b[34mEpoch: 164, Loss: 0.5504339884394563\u001b[0m\n",
      "\u001b[34mEpoch: 165, Loss: 0.5506514129483521\u001b[0m\n",
      "\u001b[34mEpoch: 166, Loss: 0.5507895333824979\u001b[0m\n",
      "\u001b[34mEpoch: 167, Loss: 0.5509648279332267\u001b[0m\n",
      "\u001b[34mEpoch: 168, Loss: 0.5503626141208834\u001b[0m\n",
      "\u001b[34mEpoch: 169, Loss: 0.5505522832916248\u001b[0m\n",
      "\u001b[34mEpoch: 170, Loss: 0.550503283674909\u001b[0m\n",
      "\u001b[34mEpoch: 171, Loss: 0.5501915779480997\u001b[0m\n",
      "\u001b[34mEpoch: 172, Loss: 0.5505574478387609\u001b[0m\n",
      "\u001b[34mEpoch: 173, Loss: 0.5503277932269296\u001b[0m\n",
      "\u001b[34mEpoch: 174, Loss: 0.5502970847046554\u001b[0m\n",
      "\u001b[34mEpoch: 175, Loss: 0.5504157682427306\u001b[0m\n",
      "\u001b[34mEpoch: 176, Loss: 0.550271867120757\u001b[0m\n",
      "\u001b[34mEpoch: 177, Loss: 0.5508300706576765\u001b[0m\n",
      "\u001b[34mEpoch: 178, Loss: 0.5509804425670413\u001b[0m\n",
      "\u001b[34mEpoch: 179, Loss: 0.5502103677989169\u001b[0m\n",
      "\u001b[34mEpoch: 180, Loss: 0.5509470484285766\u001b[0m\n",
      "\u001b[34mEpoch: 181, Loss: 0.5503826452133138\u001b[0m\n",
      "\u001b[34mEpoch: 182, Loss: 0.5509576491816214\u001b[0m\n",
      "\u001b[34mEpoch: 183, Loss: 0.5502109037691287\u001b[0m\n",
      "\u001b[34mEpoch: 184, Loss: 0.5501172166024701\u001b[0m\n",
      "\u001b[34mEpoch: 185, Loss: 0.5505796725941955\u001b[0m\n",
      "\u001b[34mEpoch: 186, Loss: 0.5505632120209017\u001b[0m\n",
      "\u001b[34mEpoch: 187, Loss: 0.550248701786727\u001b[0m\n",
      "\u001b[34mEpoch: 188, Loss: 0.5508378754366426\u001b[0m\n",
      "\u001b[34mEpoch: 189, Loss: 0.5498729851557298\u001b[0m\n",
      "\u001b[34mEpoch: 190, Loss: 0.550267473664065\u001b[0m\n",
      "\u001b[34mEpoch: 191, Loss: 0.5502539863384395\u001b[0m\n",
      "\u001b[34mEpoch: 192, Loss: 0.5503650597195501\u001b[0m\n",
      "\u001b[34mEpoch: 193, Loss: 0.5506821242694775\u001b[0m\n",
      "\u001b[34mEpoch: 194, Loss: 0.5500769654547008\u001b[0m\n",
      "\u001b[34mEpoch: 195, Loss: 0.5502448046447409\u001b[0m\n",
      "\u001b[34mEpoch: 196, Loss: 0.5501548501185041\u001b[0m\n",
      "\u001b[34mEpoch: 197, Loss: 0.5505297931922732\u001b[0m\n",
      "\u001b[34mEpoch: 198, Loss: 0.5498256643864323\u001b[0m\n",
      "\u001b[34mEpoch: 199, Loss: 0.5507231660689531\u001b[0m\n",
      "\n",
      "2020-08-03 01:33:31 Uploading - Uploading generated training model\n",
      "2020-08-03 01:33:31 Completed - Training job completed\n",
      "\u001b[34mEpoch: 200, Loss: 0.5500568160431438\u001b[0m\n",
      "\u001b[34m2020-08-03 01:33:21,096 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "Training seconds: 1095\n",
      "Billable seconds: 1095\n"
     ]
    }
   ],
   "source": [
    "# import a PyTorch wrapper\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "# specify an output path\n",
    "output_path = f\"s3://{bucket}/{prefix}-5-hidden-layer\"\n",
    "\n",
    "# instantiate a pytorch estimator\n",
    "estimator = PyTorch(\n",
    "    entry_point=\"train.py\",\n",
    "    source_dir=\"pytorch\",\n",
    "    role=role,\n",
    "    framework_version=\"1.0\",\n",
    "    train_instance_count=1,\n",
    "    train_instance_type=\"ml.c4.xlarge\",\n",
    "    output_path=output_path,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    hyperparameters={\n",
    "        \"input_features\": 19,\n",
    "        \"hidden_dim\": 180, \n",
    "        \"output_dim\": 1,\n",
    "        \"epochs\": 200\n",
    "    })\n",
    "estimator.fit({'train': s3_input_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    }
   ],
   "source": [
    "# Deploy the trained model\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "model = PyTorchModel(\n",
    "    entry_point=\"predict.py\",\n",
    "    role=role, \n",
    "    framework_version=\"1.0\",\n",
    "    model_data=estimator.model_data,\n",
    "    source_dir=\"pytorch\"\n",
    ")\n",
    "\n",
    "# deploy your model to create a predictor\n",
    "predictor = model.deploy(initial_instance_count=1, instance_type=\"ml.t2.medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:10: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n"
     ]
    }
   ],
   "source": [
    "# evaluating the model\n",
    "# read in test data, assuming it is stored locally\n",
    "test_data = pd.read_csv(\"data/test_full.csv\", header=None, names=None)\n",
    "\n",
    "# labels are in the first column\n",
    "test_y = test_data.iloc[:,0]\n",
    "test_x = test_data.iloc[:,1:]\n",
    "test_y_preds = np.hstack(\n",
    "    predictor.predict(test_x.iloc[i: i+1000]).reshape(1, -1).squeeze() \n",
    "    for i in range(0, len(test_x), 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6102643311052031"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the test roc_auc_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(test_y, test_y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6479330114665057"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(test_y, test_y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5921167628037056"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(test_y, test_y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
